{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haoying/anaconda3/envs/torch/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_space\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import geoio\n",
    "import convert as conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('/home/haoying/data_zl12/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['name'] = images\n",
    "\n",
    "data['cluster_lat'] = [conv.num2deg(conv.deg2num(float(x.strip('.png').split('_')[1]),float(x.strip('.png').split('_')[0]),12)[1],conv.deg2num(float(x.strip('.png').split('_')[1]),float(x.strip('.png').split('_')[0]),12)[0],12)[0] for x in images]\n",
    "data['cluster_lon'] = [conv.num2deg(conv.deg2num(float(x.strip('.png').split('_')[1]),float(x.strip('.png').split('_')[0]),12)[1],conv.deg2num(float(x.strip('.png').split('_')[1]),float(x.strip('.png').split('_')[0]),12)[0],12)[1] for x in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-48.779296875_-66.93006025862447.png</td>\n",
       "      <td>43.771094</td>\n",
       "      <td>90.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-44.82421875_-75.97355295343337.png</td>\n",
       "      <td>40.847060</td>\n",
       "      <td>120.058594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.82421875_-70.98834922412489.png</td>\n",
       "      <td>40.847060</td>\n",
       "      <td>102.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-39.111328125_-65.4034447883078.png</td>\n",
       "      <td>36.385913</td>\n",
       "      <td>87.275391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-50.80078125_-77.86034459764656.png</td>\n",
       "      <td>45.213004</td>\n",
       "      <td>128.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131947</th>\n",
       "      <td>-38.671875_-69.28725695167886.png</td>\n",
       "      <td>36.031332</td>\n",
       "      <td>97.382812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131948</th>\n",
       "      <td>-46.142578125_-72.63337363853837.png</td>\n",
       "      <td>41.836828</td>\n",
       "      <td>107.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131949</th>\n",
       "      <td>-44.208984375_-66.08936427047087.png</td>\n",
       "      <td>40.380028</td>\n",
       "      <td>88.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131950</th>\n",
       "      <td>-25.224609375_-74.59010800882324.png</td>\n",
       "      <td>24.447150</td>\n",
       "      <td>114.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131951</th>\n",
       "      <td>-51.6796875_-64.35893097894458.png</td>\n",
       "      <td>45.828799</td>\n",
       "      <td>84.814453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name  cluster_lat  cluster_lon\n",
       "0       -48.779296875_-66.93006025862447.png    43.771094    90.966797\n",
       "1        -44.82421875_-75.97355295343337.png    40.847060   120.058594\n",
       "2        -44.82421875_-70.98834922412489.png    40.847060   102.304688\n",
       "3        -39.111328125_-65.4034447883078.png    36.385913    87.275391\n",
       "4        -50.80078125_-77.86034459764656.png    45.213004   128.320312\n",
       "...                                      ...          ...          ...\n",
       "131947     -38.671875_-69.28725695167886.png    36.031332    97.382812\n",
       "131948  -46.142578125_-72.63337363853837.png    41.836828   107.666016\n",
       "131949  -44.208984375_-66.08936427047087.png    40.380028    88.945312\n",
       "131950  -25.224609375_-74.59010800882324.png    24.447150   114.609375\n",
       "131951    -51.6796875_-64.35893097894458.png    45.828799    84.814453\n",
       "\n",
       "[131952 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIGHTLIGHTS_DIR = '/home/haoying/VNL_v2_npp_2020_global_vcmslcfg_c202101211500.average.tif'\n",
    "tif = geoio.GeoImage(NIGHTLIGHTS_DIR)\n",
    "tif_array = np.squeeze(tif.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nightlights(df, tif, tif_array):\n",
    "    ''' \n",
    "    This takes a dataframe with columns cluster_lat, cluster_lon and finds the average \n",
    "    nightlights in 2015 using a 10kmx10km box around the point\n",
    "    \n",
    "    I try all the nighlights tifs until a match is found, or none are left upon which an error is raised\n",
    "    '''\n",
    "    cluster_nightlights = []\n",
    "    for i,r in df.iterrows():\n",
    "        min_lat, min_lon, max_lat, max_lon = create_space(r.cluster_lat, r.cluster_lon,s=9.7)\n",
    "        \n",
    "        xminPixel, ymaxPixel = tif.proj_to_raster(min_lon, min_lat)\n",
    "        xmaxPixel, yminPixel = tif.proj_to_raster(max_lon, max_lat)\n",
    "        assert xminPixel < xmaxPixel, print(r.cluster_lat, r.cluster_lon)\n",
    "        assert yminPixel < ymaxPixel, print(r.cluster_lat, r.cluster_lon)\n",
    "        if xminPixel < 0 or xmaxPixel >= tif_array.shape[1]:\n",
    "            print(f\"no match for {r.cluster_lat}, {r.cluster_lon}\")\n",
    "            raise ValueError()\n",
    "        elif yminPixel < 0 or ymaxPixel >= tif_array.shape[0]:\n",
    "            print(f\"no match for {r.cluster_lat}, {r.cluster_lon}\")\n",
    "            raise ValueError()\n",
    "        xminPixel, yminPixel, xmaxPixel, ymaxPixel = int(xminPixel), int(yminPixel), int(xmaxPixel), int(ymaxPixel)\n",
    "        cluster_nightlights.append(tif_array[yminPixel:ymaxPixel,xminPixel:xmaxPixel].mean())\n",
    "        \n",
    "    df['nightlights'] = cluster_nightlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nightlights(data, tif, tif_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>nightlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-48.779296875_-66.93006025862447.png</td>\n",
       "      <td>43.771094</td>\n",
       "      <td>90.966797</td>\n",
       "      <td>0.377887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-44.82421875_-75.97355295343337.png</td>\n",
       "      <td>40.847060</td>\n",
       "      <td>120.058594</td>\n",
       "      <td>0.398727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.82421875_-70.98834922412489.png</td>\n",
       "      <td>40.847060</td>\n",
       "      <td>102.304688</td>\n",
       "      <td>0.272418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-39.111328125_-65.4034447883078.png</td>\n",
       "      <td>36.385913</td>\n",
       "      <td>87.275391</td>\n",
       "      <td>0.388664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-50.80078125_-77.86034459764656.png</td>\n",
       "      <td>45.213004</td>\n",
       "      <td>128.320312</td>\n",
       "      <td>0.308112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  cluster_lat  cluster_lon  nightlights\n",
       "0  -48.779296875_-66.93006025862447.png    43.771094    90.966797     0.377887\n",
       "1   -44.82421875_-75.97355295343337.png    40.847060   120.058594     0.398727\n",
       "2   -44.82421875_-70.98834922412489.png    40.847060   102.304688     0.272418\n",
       "3   -39.111328125_-65.4034447883078.png    36.385913    87.275391     0.388664\n",
       "4   -50.80078125_-77.86034459764656.png    45.213004   128.320312     0.308112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cluster_lon','cluster_lat']].to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/position.csv',index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['y_x','cluster_lat','cluster_lon','nightlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "import requests\n",
    "#import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights.csv')\n",
    "data.columns=['y_x','cluster_lat','cluster_lon','nightlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.046055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "np.percentile(data['nightlights'], 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125353"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max95 = np.percentile(data['nightlights'], 97.5)\n",
    "min5 = np.percentile(data['nightlights'], 2.5)\n",
    "data = data[(data['nightlights']<max95)&(data['nightlights']>min5)]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "X = data['nightlights'].values.reshape(-1,1)\n",
    "gmm = GMM(n_components=3).fit(X)\n",
    "labels = gmm.predict(data['nightlights'].values.reshape(-1,1))\n",
    "\n",
    "n_components = np.arange(1, 21)\n",
    "models = [GMM(n, covariance_type='full', random_state=0).fit(X)\n",
    "          for n in n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'n_components')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39044592, 3.0458412, 0.7466203)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label0_max = data['nightlights'][labels==0].max()\n",
    "label1_max = data['nightlights'][labels==1].max()\n",
    "label2_max = data['nightlights'][labels==2].max()\n",
    "\n",
    "label0_max, label1_max, label2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoying/anaconda3/envs/torch/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.752156\n",
       "1    0.172952\n",
       "2    0.074893\n",
       "Name: nightlights_bin, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_nightlights_bin(df, cutoffs):\n",
    "    assert len(cutoffs) >= 2, print('need at least 2 bins')\n",
    "    cutoffs = sorted(cutoffs, reverse=True)\n",
    "    labels = list(range(len(cutoffs)))[::-1]\n",
    "    df['nightlights_bin'] = len(cutoffs)\n",
    "    for cutoff, label in zip(cutoffs, labels):\n",
    "        df['nightlights_bin'].loc[df['nightlights'] <= cutoff] = label\n",
    "\n",
    "data_final = data.copy()\n",
    "create_nightlights_bin(data_final, cutoffs=[label0_max, label1_max, label2_max])\n",
    "data_final['nightlights_bin'].value_counts()/len(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=1\n",
    "MIN_IMAGES_PER_CLUSTER=10\n",
    "def drop_in_range(df, lower=0, upper=2, fr=0.25):\n",
    "    \"\"\"\n",
    "        Very similar to drop_0s calculation, but more generalized. Lower and upper are inclusive.\n",
    "    \"\"\"\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    boolean_idx = ((lower <= df['nightlights']) & (df['nightlights'] <= upper))\n",
    "    c_under = boolean_idx.sum()\n",
    "    n = len(df)\n",
    "    assert c_under / n > fr, print(f'Dataframe already has under {fr} rows in the given range')\n",
    "    \n",
    "    d = (c_under - n * fr) / (1 - fr)\n",
    "    d = int(d)\n",
    "    print(f'dropping: {d}')\n",
    "    \n",
    "    select_df = df[boolean_idx]\n",
    "    \n",
    "    \n",
    "    drop_inds = random.sample(select_df.index.tolist(), d)\n",
    "        \n",
    "    return df.drop(drop_inds).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping: 86387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38966"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_drop2 = drop_in_range(data, lower=0, upper=0.39, fr=0.2)\n",
    "len(data_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20002053071908843"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_drop2['nightlights']<0.39).sum()/len(data_drop2['nightlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854726559680485"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_drop2['nightlights']<1).sum()/len(data_drop2['nightlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop2[['cluster_lon','cluster_lat']].to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/position_drop.csv',index=False,encoding='utf_8_sig')\n",
    "data_drop2.to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_drop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label0_max = data_drop2['nightlights'][labels==0].max()\n",
    "# label1_max = data_drop2['nightlights'][labels==1].max()\n",
    "# label2_max = data_drop2['nightlights'][labels==2].max()\n",
    "\n",
    "# label0_max, label1_max, label2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0_max = 0.39\n",
    "label1_max = 0.74\n",
    "label2_max = 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_drop2.copy()\n",
    "create_nightlights_bin(data_final, cutoffs=[label0_max, label1_max, label2_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.556177\n",
       "2    0.243802\n",
       "0    0.200021\n",
       "Name: nightlights_bin, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['nightlights_bin'].value_counts()/len(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final[data_final['nightlights_bin'] == 0].to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled0.csv', index = False)\n",
    "data_final[data_final['nightlights_bin'] == 1].to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled1.csv', index = False)\n",
    "data_final[data_final['nightlights_bin'] == 2].to_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_space\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import geoio\n",
    "import convert as conv\n",
    "data_final0 = pd.read_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled0.csv')\n",
    "data_final1 = pd.read_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled1.csv')\n",
    "data_final2 = pd.read_csv('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['/home/haoying/data_zl12/' + x for x in data_final2['y_x'].tolist()]\n",
    "labels = data_final2['nightlights'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "#import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from skimage import io,transform\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset): #继承Dataset\n",
    "    def __init__(self,transform=None): #__init__是初始化该类的一些基础参数\n",
    "\n",
    "        self.transform = transform #变换\n",
    "        self.images = images#目录里的所有文件\n",
    "        self.label = labels\n",
    "    \n",
    "    def __len__(self):#返回整个数据集的大小\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):#根据索引index返回dataset[index]\n",
    "        img_path = self.images[index]#根据索引index获取该图片\n",
    "        img = Image.open(img_path).convert(\"RGB\")# 读取该图片\n",
    "        if self.transform:\n",
    "            img = self.transform(img)#对样本进行变换\n",
    "        return img, self.label[index] #返回该样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor()])\n",
    "data = Data(transform = transform)\n",
    "dataloader = DataLoader(data, batch_size=50, shuffle=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (7): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (10): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (13): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (14): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet \n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "feature = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features=feature,out_features=1,bias=True)\n",
    "# model = nn.Sequential(*(list(model.children())))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  9500\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples: ', len(data))\n",
    "num=0\n",
    "model=model.cuda()\n",
    "# model = torch.load('trained_model.pt', map_location=torch.device('cpu')).cuda(num)\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion = torch.nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################\n",
      " Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoying/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 104.6339146643877\n",
      "##################################\n",
      " Epoch 1:\n",
      "1 69.67763143777847\n",
      "##################################\n",
      " Epoch 2:\n",
      "2 68.79084450006485\n",
      "##################################\n",
      " Epoch 3:\n",
      "3 68.48738677799702\n",
      "##################################\n",
      " Epoch 4:\n",
      "4 68.11787043511868\n",
      "##################################\n",
      " Epoch 5:\n",
      "5 68.25035187602043\n",
      "##################################\n",
      " Epoch 6:\n",
      "6 67.81649187207222\n",
      "##################################\n",
      " Epoch 7:\n",
      "7 68.08522732555866\n",
      "##################################\n",
      " Epoch 8:\n",
      "8 67.57619842886925\n",
      "##################################\n",
      " Epoch 9:\n",
      "9 67.52380713820457\n",
      "##################################\n",
      " Epoch 10:\n",
      "10 67.38299642503262\n",
      "##################################\n",
      " Epoch 11:\n",
      "11 67.56435322761536\n",
      "##################################\n",
      " Epoch 12:\n",
      "12 67.39975513517857\n",
      "##################################\n",
      " Epoch 13:\n",
      "13 67.43298442661762\n",
      "##################################\n",
      " Epoch 14:\n",
      "14 67.31190240383148\n",
      "##################################\n",
      " Epoch 15:\n",
      "15 67.18573816120625\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(16):\n",
    "    l = 0\n",
    "    accu = 0\n",
    "    print('##################################\\n Epoch {}:'.format(epoch))\n",
    "    for batch_idx,(input,label) in enumerate(dataloader):\n",
    "        input,label=input.cuda(),label.float().cuda()       \n",
    "        output= model(input)        \n",
    "        loss = criterion(output,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l += loss.data.item()\n",
    "    print(epoch, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/haoying/res_zl12_effnet_b0_9.7km/')\n",
    "torch.save(model, 'label2_pretrained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
