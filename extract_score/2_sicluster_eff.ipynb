{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSDataset(Dataset):\n",
    "    def __init__(self, metadata, root_dir,transform1=None, transform2=None):\n",
    "        self.metadata = pd.read_csv(metadata).values\n",
    "        self.root_dir = root_dir\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.metadata[idx][0])\n",
    "        image =  Image.open(img_name).convert('RGB')\n",
    "        if self.transform1:\n",
    "            img1 = self.transform1(image)\n",
    "        if self.transform2:\n",
    "            img2 = self.transform2(image)\n",
    "            return img1, img2, idx\n",
    "                \n",
    "        return img1, idx\n",
    "\n",
    "class AUGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AUGLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        b = (x1 - x2)\n",
    "        b = b*b\n",
    "        b = b.sum(1)\n",
    "        b = torch.sqrt(b)\n",
    "        return b.sum()\n",
    "\n",
    "# Below codes are from Deep Clustering for Unsupervised Learning of Visual Features github code        \n",
    "def preprocess_features(npdata, pca):\n",
    "    _, ndim = npdata.shape\n",
    "    npdata =  npdata.astype('float32')\n",
    "\n",
    "    # Apply PCA-whitening with Faiss\n",
    "    mat = faiss.PCAMatrix (ndim, pca, eigen_power=-0.5)\n",
    "    mat.train(npdata)\n",
    "    assert mat.is_trained\n",
    "    npdata = mat.apply_py(npdata)\n",
    "\n",
    "    # L2 normalization\n",
    "    row_sums = np.linalg.norm(npdata, axis=1)\n",
    "    npdata = npdata / row_sums[:, np.newaxis]\n",
    "\n",
    "    return npdata\n",
    "\n",
    "def cluster_assign(images_lists, dataset):\n",
    "    assert images_lists is not None\n",
    "    pseudolabels = []\n",
    "    image_indexes = []\n",
    "    for cluster, images in enumerate(images_lists):\n",
    "        image_indexes.extend(images)\n",
    "        pseudolabels.extend([cluster] * len(images))\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    t = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            normalize])\n",
    "\n",
    "    return ReassignedDataset(image_indexes, pseudolabels, dataset, t)\n",
    "\n",
    "\n",
    "def run_kmeans(x, nmb_clusters):\n",
    "    n_data, d = x.shape\n",
    "\n",
    "    # faiss implementation of k-means\n",
    "    clus = faiss.Clustering(d, nmb_clusters)\n",
    "\n",
    "    # Change faiss seed at each k-means so that the randomly picked\n",
    "    # initialization centroids do not correspond to the same feature ids\n",
    "    # from an epoch to another.\n",
    "    clus.seed = np.random.randint(1234)\n",
    "\n",
    "    clus.niter = 20\n",
    "    clus.max_points_per_centroid = 10000000\n",
    "    res = faiss.StandardGpuResources()\n",
    "    flat_config = faiss.GpuIndexFlatConfig()\n",
    "    flat_config.useFloat16 = False\n",
    "    flat_config.device = 0\n",
    "    index = faiss.GpuIndexFlatL2(res, d, flat_config)\n",
    "\n",
    "    # perform the training\n",
    "    clus.train(x, index)\n",
    "    _, I = index.search(x, 1)\n",
    "#     losses = faiss.vector_to_array(clus.obj)\n",
    "    stats = clus.iteration_stats\n",
    "    losses = np.array([stats.at(i).obj for i in range(stats.size())])\n",
    "    print('k-means loss evolution: {0}'.format(losses))\n",
    "\n",
    "    return [int(n[0]) for n in I], losses[-1]\n",
    "\n",
    "\n",
    "def compute_features(dataloader, model, N, batch_size):\n",
    "    model.eval()\n",
    "    # discard the label information in the dataloader\n",
    "    for i, (inputs, _) in enumerate(dataloader):\n",
    "        inputs = inputs.cuda()\n",
    "        aux = model(inputs).data.cpu().numpy()\n",
    "        aux = aux.reshape(-1, 1280)\n",
    "        if i == 0:\n",
    "            features = np.zeros((N, aux.shape[1]), dtype='float32')\n",
    "\n",
    "        aux = aux.astype('float32')\n",
    "        if i < len(dataloader) - 1:\n",
    "            features[i * batch_size: (i + 1) * batch_size] = aux\n",
    "        else:\n",
    "            features[i * batch_size:] = aux\n",
    "\n",
    "    return features  \n",
    "\n",
    "\n",
    "class Kmeans(object):\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def cluster(self, data,pca):\n",
    "        end = time.time()\n",
    "\n",
    "        # PCA-reducing, whitening and L2-normalization\n",
    "        xb = preprocess_features(data,pca)\n",
    "\n",
    "        # cluster the data\n",
    "        I, loss = run_kmeans(xb, self.k)\n",
    "        self.images_lists = [[] for i in range(self.k)]\n",
    "        label = []\n",
    "        for i in range(len(data)):\n",
    "            label.append(I[i])\n",
    "            self.images_lists[I[i]].append(i)\n",
    "            \n",
    "        label = torch.tensor(label).cuda()\n",
    "        print(label)\n",
    "\n",
    "        print('k-means time: {0:.0f} s'.format(time.time() - end))\n",
    "\n",
    "        return loss, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed_all(3)\n",
    "np.random.seed(3)\n",
    "\n",
    "model = torch.load('/home/haoying/res_zl12_effnet_b0_9.7km/res_pretrained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = model._fc.in_features\n",
    "# model._fc = nn.Linear(in_features=feature,out_features=3,bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._fc = nn.Identity()\n",
    "model._swish = nn.Identity()\n",
    "# model = nn.Sequential(*(list(model.children())[:-3])) # strips off last linear layer\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_transform =transforms.Compose([\n",
    "                      transforms.Resize(256),\n",
    "                      transforms.CenterCrop(224),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "train_transform1 =transforms.Compose([\n",
    "                      transforms.Resize(256),\n",
    "                      transforms.CenterCrop(224),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.RandomVerticalFlip(),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "train_transform2 =transforms.Compose([\n",
    "                      transforms.Resize(256),\n",
    "                      transforms.CenterCrop(224),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.RandomVerticalFlip(),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion2 = AUGLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rural\n",
    "clusterset = GPSDataset('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled1.csv', '/home/haoying/data_zl12/', cluster_transform)\n",
    "trainset = GPSDataset('/home/haoying/res_zl12_effnet_b0_9.7km/nightlights_labeled1.csv', '/home/haoying/data_zl12/', train_transform1, train_transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19397 9125 9214\n"
     ]
    }
   ],
   "source": [
    "ddf1 = pd.read_csv('/home/haoying/res_zl12_effnet_v4/nightlights_labeled1.csv')\n",
    "ddf2 = pd.read_csv('/home/haoying/res_zl12_effnet_v4/nightlights_labeled2.csv')\n",
    "ddf0 = pd.read_csv('/home/haoying/res_zl12_effnet_v4/nightlights_labeled0.csv')\n",
    "\n",
    "print(len(ddf1),len(ddf2),len(ddf0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means loss evolution: [12055.38769531  7210.95703125  6853.24609375  6726.71240234\n",
      "  6666.53662109  6633.046875    6610.97021484  6590.04882812\n",
      "  6569.46142578  6554.92041016  6543.77197266  6535.80712891\n",
      "  6531.55126953  6529.04101562  6527.16748047  6525.515625\n",
      "  6524.50341797  6523.54736328  6522.63427734  6522.15332031]\n",
      "tensor([4, 3, 2,  ..., 2, 4, 2], device='cuda:0')\n",
      "k-means time: 6 s\n"
     ]
    }
   ],
   "source": [
    "clusterloader = torch.utils.data.DataLoader(clusterset, batch_size=30, shuffle=False, num_workers=0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=30, shuffle=True, num_workers=0, drop_last = True)\n",
    "deepcluster = Kmeans(8)\n",
    "\n",
    "features = compute_features(clusterloader, model, len(clusterset),30) \n",
    "clustering_loss, p_label = deepcluster.cluster(features,pca=10)\n",
    "p_label = p_label.tolist()\n",
    "p_label = torch.tensor(p_label).cuda()\n",
    "model.train()\n",
    "\n",
    "fc = nn.Linear(1280, 8)\n",
    "fc.weight.data.normal_(0, 0.01)\n",
    "fc.bias.data.zero_()\n",
    "fc.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "optimizer1 = torch.optim.SGD(fc.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21672, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_ = features\n",
    "pca = PCA(n_components = 0.80) \n",
    "pca.fit(X_)\n",
    "reduced_X = pca.transform(X_)\n",
    "reduced_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "[BATCH_IDX :  0 LOSS :  36.797725677490234 CE_LOSS :  2.5759634971618652 AUG_LOSS :  34.221763610839844 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.96944808959961 CE_LOSS :  1.6660598516464233 AUG_LOSS :  34.30338668823242 ]\n",
      "[BATCH_IDX :  40 LOSS :  34.961509704589844 CE_LOSS :  1.3149278163909912 AUG_LOSS :  33.646583557128906 ]\n",
      "[BATCH_IDX :  60 LOSS :  36.10052490234375 CE_LOSS :  1.6823190450668335 AUG_LOSS :  34.41820526123047 ]\n",
      "[BATCH_IDX :  80 LOSS :  35.3938102722168 CE_LOSS :  1.6207516193389893 AUG_LOSS :  33.7730598449707 ]\n",
      "[BATCH_IDX :  100 LOSS :  36.46091842651367 CE_LOSS :  1.9249355792999268 AUG_LOSS :  34.53598403930664 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.322486877441406 CE_LOSS :  1.713403344154358 AUG_LOSS :  33.60908508300781 ]\n",
      "[BATCH_IDX :  140 LOSS :  35.98539733886719 CE_LOSS :  1.5343314409255981 AUG_LOSS :  34.45106506347656 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.101646423339844 CE_LOSS :  1.9689923524856567 AUG_LOSS :  33.132652282714844 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.90697479248047 CE_LOSS :  1.821812391281128 AUG_LOSS :  34.08516311645508 ]\n",
      "[BATCH_IDX :  200 LOSS :  36.36564636230469 CE_LOSS :  1.3998706340789795 AUG_LOSS :  34.96577453613281 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.34743881225586 CE_LOSS :  1.6089469194412231 AUG_LOSS :  33.73849105834961 ]\n",
      "[BATCH_IDX :  240 LOSS :  36.06538772583008 CE_LOSS :  1.9209530353546143 AUG_LOSS :  34.14443588256836 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.74531936645508 CE_LOSS :  1.443631649017334 AUG_LOSS :  34.30168914794922 ]\n",
      "[BATCH_IDX :  280 LOSS :  36.04343032836914 CE_LOSS :  1.6161726713180542 AUG_LOSS :  34.4272575378418 ]\n",
      "[BATCH_IDX :  300 LOSS :  36.164371490478516 CE_LOSS :  1.4659806489944458 AUG_LOSS :  34.69839096069336 ]\n",
      "[BATCH_IDX :  320 LOSS :  36.37966537475586 CE_LOSS :  1.5909990072250366 AUG_LOSS :  34.788665771484375 ]\n",
      "[BATCH_IDX :  340 LOSS :  36.093326568603516 CE_LOSS :  1.3933398723602295 AUG_LOSS :  34.69998550415039 ]\n",
      "[BATCH_IDX :  360 LOSS :  36.482276916503906 CE_LOSS :  1.8118159770965576 AUG_LOSS :  34.67045974731445 ]\n",
      "[BATCH_IDX :  380 LOSS :  36.4117546081543 CE_LOSS :  1.666555643081665 AUG_LOSS :  34.74519729614258 ]\n",
      "[BATCH_IDX :  400 LOSS :  34.884334564208984 CE_LOSS :  1.346494197845459 AUG_LOSS :  33.537841796875 ]\n",
      "[BATCH_IDX :  420 LOSS :  36.252586364746094 CE_LOSS :  1.6691848039627075 AUG_LOSS :  34.58340072631836 ]\n",
      "[BATCH_IDX :  440 LOSS :  35.896331787109375 CE_LOSS :  1.3391709327697754 AUG_LOSS :  34.557159423828125 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.10559844970703 CE_LOSS :  1.5084348917007446 AUG_LOSS :  33.597164154052734 ]\n",
      "[BATCH_IDX :  480 LOSS :  34.623069763183594 CE_LOSS :  1.3007466793060303 AUG_LOSS :  33.322322845458984 ]\n",
      "[BATCH_IDX :  500 LOSS :  35.79621505737305 CE_LOSS :  1.5142326354980469 AUG_LOSS :  34.281982421875 ]\n",
      "[BATCH_IDX :  520 LOSS :  35.236297607421875 CE_LOSS :  1.3571574687957764 AUG_LOSS :  33.8791389465332 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.16048049926758 CE_LOSS :  1.1716333627700806 AUG_LOSS :  33.98884582519531 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.79542541503906 CE_LOSS :  1.3943455219268799 AUG_LOSS :  34.40108108520508 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.599708557128906 CE_LOSS :  1.3790383338928223 AUG_LOSS :  34.22066879272461 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.37111282348633 CE_LOSS :  1.3981804847717285 AUG_LOSS :  33.972930908203125 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.673526763916016 CE_LOSS :  1.459000825881958 AUG_LOSS :  34.21452713012695 ]\n",
      "[BATCH_IDX :  640 LOSS :  34.731834411621094 CE_LOSS :  1.3112456798553467 AUG_LOSS :  33.420589447021484 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.148094177246094 CE_LOSS :  1.4881095886230469 AUG_LOSS :  33.65998458862305 ]\n",
      "[BATCH_IDX :  680 LOSS :  36.3703498840332 CE_LOSS :  1.1661776304244995 AUG_LOSS :  35.20417404174805 ]\n",
      "[BATCH_IDX :  700 LOSS :  36.34855651855469 CE_LOSS :  1.2514402866363525 AUG_LOSS :  35.09711456298828 ]\n",
      "[BATCH_IDX :  720 LOSS :  36.16278076171875 CE_LOSS :  1.727303385734558 AUG_LOSS :  34.43547821044922 ]\n",
      "Epoch : 1\n",
      "[BATCH_IDX :  0 LOSS :  35.92856216430664 CE_LOSS :  1.5223520994186401 AUG_LOSS :  34.406211853027344 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.89433670043945 CE_LOSS :  1.7337079048156738 AUG_LOSS :  34.16062927246094 ]\n",
      "[BATCH_IDX :  40 LOSS :  36.08277130126953 CE_LOSS :  1.6655528545379639 AUG_LOSS :  34.41721725463867 ]\n",
      "[BATCH_IDX :  60 LOSS :  36.29773712158203 CE_LOSS :  1.6899083852767944 AUG_LOSS :  34.60783004760742 ]\n",
      "[BATCH_IDX :  80 LOSS :  36.63479995727539 CE_LOSS :  1.3218830823898315 AUG_LOSS :  35.31291580200195 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.58359909057617 CE_LOSS :  1.3852254152297974 AUG_LOSS :  34.19837188720703 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.32329559326172 CE_LOSS :  1.3366878032684326 AUG_LOSS :  33.98660659790039 ]\n",
      "[BATCH_IDX :  140 LOSS :  36.31418991088867 CE_LOSS :  1.9526649713516235 AUG_LOSS :  34.36152648925781 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.884925842285156 CE_LOSS :  1.707471489906311 AUG_LOSS :  34.17745590209961 ]\n",
      "[BATCH_IDX :  180 LOSS :  36.89898681640625 CE_LOSS :  1.7652777433395386 AUG_LOSS :  35.13370895385742 ]\n",
      "[BATCH_IDX :  200 LOSS :  35.63552474975586 CE_LOSS :  1.3215525150299072 AUG_LOSS :  34.31397247314453 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.18375778198242 CE_LOSS :  1.4302551746368408 AUG_LOSS :  33.753501892089844 ]\n",
      "[BATCH_IDX :  240 LOSS :  36.328590393066406 CE_LOSS :  1.4992035627365112 AUG_LOSS :  34.82938766479492 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.51052474975586 CE_LOSS :  1.7007938623428345 AUG_LOSS :  33.809730529785156 ]\n",
      "[BATCH_IDX :  280 LOSS :  35.146514892578125 CE_LOSS :  1.3438684940338135 AUG_LOSS :  33.80264663696289 ]\n",
      "[BATCH_IDX :  300 LOSS :  35.44271469116211 CE_LOSS :  1.7634952068328857 AUG_LOSS :  33.67921829223633 ]\n",
      "[BATCH_IDX :  320 LOSS :  36.323856353759766 CE_LOSS :  1.4886090755462646 AUG_LOSS :  34.83524703979492 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.88959503173828 CE_LOSS :  1.24713933467865 AUG_LOSS :  34.6424560546875 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.36699676513672 CE_LOSS :  1.4217318296432495 AUG_LOSS :  33.94526672363281 ]\n",
      "[BATCH_IDX :  380 LOSS :  36.1835823059082 CE_LOSS :  2.03951358795166 AUG_LOSS :  34.14406967163086 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.16481018066406 CE_LOSS :  1.335371732711792 AUG_LOSS :  33.829437255859375 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.87325668334961 CE_LOSS :  1.568967580795288 AUG_LOSS :  34.304290771484375 ]\n",
      "[BATCH_IDX :  440 LOSS :  36.087772369384766 CE_LOSS :  1.4486998319625854 AUG_LOSS :  34.63907241821289 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.33588790893555 CE_LOSS :  1.361294150352478 AUG_LOSS :  33.97459411621094 ]\n",
      "[BATCH_IDX :  480 LOSS :  36.630672454833984 CE_LOSS :  1.5514638423919678 AUG_LOSS :  35.07920837402344 ]\n",
      "[BATCH_IDX :  500 LOSS :  35.91142654418945 CE_LOSS :  1.43386971950531 AUG_LOSS :  34.47755813598633 ]\n",
      "[BATCH_IDX :  520 LOSS :  36.561920166015625 CE_LOSS :  1.573862075805664 AUG_LOSS :  34.988059997558594 ]\n",
      "[BATCH_IDX :  540 LOSS :  36.129432678222656 CE_LOSS :  1.4851776361465454 AUG_LOSS :  34.644256591796875 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.365474700927734 CE_LOSS :  1.4981635808944702 AUG_LOSS :  33.8673095703125 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.60553741455078 CE_LOSS :  1.4559683799743652 AUG_LOSS :  34.14957046508789 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.01121139526367 CE_LOSS :  1.2272802591323853 AUG_LOSS :  33.783931732177734 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.5126838684082 CE_LOSS :  1.2670891284942627 AUG_LOSS :  34.2455940246582 ]\n",
      "[BATCH_IDX :  640 LOSS :  35.91163635253906 CE_LOSS :  1.512111783027649 AUG_LOSS :  34.3995246887207 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.02320861816406 CE_LOSS :  1.3783459663391113 AUG_LOSS :  33.64486312866211 ]\n",
      "[BATCH_IDX :  680 LOSS :  36.5524787902832 CE_LOSS :  1.4266128540039062 AUG_LOSS :  35.1258659362793 ]\n",
      "[BATCH_IDX :  700 LOSS :  35.66877746582031 CE_LOSS :  1.289734125137329 AUG_LOSS :  34.37904357910156 ]\n",
      "[BATCH_IDX :  720 LOSS :  35.40748977661133 CE_LOSS :  1.4950963258743286 AUG_LOSS :  33.912391662597656 ]\n",
      "Epoch : 2\n",
      "[BATCH_IDX :  0 LOSS :  35.1063117980957 CE_LOSS :  1.1835196018218994 AUG_LOSS :  33.92279052734375 ]\n",
      "[BATCH_IDX :  20 LOSS :  36.32366180419922 CE_LOSS :  1.4599318504333496 AUG_LOSS :  34.863731384277344 ]\n",
      "[BATCH_IDX :  40 LOSS :  35.129581451416016 CE_LOSS :  1.472495675086975 AUG_LOSS :  33.65708541870117 ]\n",
      "[BATCH_IDX :  60 LOSS :  36.50727844238281 CE_LOSS :  1.5226389169692993 AUG_LOSS :  34.98463821411133 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  80 LOSS :  35.91375732421875 CE_LOSS :  1.5454859733581543 AUG_LOSS :  34.36827087402344 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.39961624145508 CE_LOSS :  1.308115839958191 AUG_LOSS :  34.09149932861328 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.32647705078125 CE_LOSS :  1.5051932334899902 AUG_LOSS :  33.821285247802734 ]\n",
      "[BATCH_IDX :  140 LOSS :  35.375728607177734 CE_LOSS :  1.1032346487045288 AUG_LOSS :  34.27249526977539 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.622589111328125 CE_LOSS :  1.5080959796905518 AUG_LOSS :  34.11449432373047 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.238189697265625 CE_LOSS :  1.0033652782440186 AUG_LOSS :  34.234825134277344 ]\n",
      "[BATCH_IDX :  200 LOSS :  36.092918395996094 CE_LOSS :  1.658701777458191 AUG_LOSS :  34.4342155456543 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.33893585205078 CE_LOSS :  1.1230380535125732 AUG_LOSS :  34.21589660644531 ]\n",
      "[BATCH_IDX :  240 LOSS :  35.56914520263672 CE_LOSS :  1.3499760627746582 AUG_LOSS :  34.21916961669922 ]\n",
      "[BATCH_IDX :  260 LOSS :  36.101783752441406 CE_LOSS :  1.2381399869918823 AUG_LOSS :  34.863643646240234 ]\n",
      "[BATCH_IDX :  280 LOSS :  35.74085998535156 CE_LOSS :  1.3375937938690186 AUG_LOSS :  34.40326690673828 ]\n",
      "[BATCH_IDX :  300 LOSS :  36.394126892089844 CE_LOSS :  1.8217250108718872 AUG_LOSS :  34.57240295410156 ]\n",
      "[BATCH_IDX :  320 LOSS :  35.317935943603516 CE_LOSS :  1.3449143171310425 AUG_LOSS :  33.9730224609375 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.05860137939453 CE_LOSS :  1.3391538858413696 AUG_LOSS :  33.71944808959961 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.96278381347656 CE_LOSS :  1.4318920373916626 AUG_LOSS :  34.53089141845703 ]\n",
      "[BATCH_IDX :  380 LOSS :  35.63699722290039 CE_LOSS :  1.3591781854629517 AUG_LOSS :  34.2778205871582 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.56975555419922 CE_LOSS :  1.5336021184921265 AUG_LOSS :  34.03615188598633 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.44163513183594 CE_LOSS :  1.2765846252441406 AUG_LOSS :  34.1650505065918 ]\n",
      "[BATCH_IDX :  440 LOSS :  35.59674835205078 CE_LOSS :  1.5679149627685547 AUG_LOSS :  34.028831481933594 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.639156341552734 CE_LOSS :  1.1657198667526245 AUG_LOSS :  34.47343826293945 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.28437423706055 CE_LOSS :  1.6616166830062866 AUG_LOSS :  33.62275695800781 ]\n",
      "[BATCH_IDX :  500 LOSS :  35.81834411621094 CE_LOSS :  1.6239227056503296 AUG_LOSS :  34.194419860839844 ]\n",
      "[BATCH_IDX :  520 LOSS :  35.03886795043945 CE_LOSS :  1.3753548860549927 AUG_LOSS :  33.66351318359375 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.87678909301758 CE_LOSS :  1.4256057739257812 AUG_LOSS :  34.4511833190918 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.89725875854492 CE_LOSS :  1.6948802471160889 AUG_LOSS :  34.20237731933594 ]\n",
      "[BATCH_IDX :  580 LOSS :  36.275428771972656 CE_LOSS :  1.4987146854400635 AUG_LOSS :  34.77671432495117 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.74039077758789 CE_LOSS :  1.4326225519180298 AUG_LOSS :  34.307769775390625 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.666873931884766 CE_LOSS :  1.139069676399231 AUG_LOSS :  34.52780532836914 ]\n",
      "[BATCH_IDX :  640 LOSS :  36.3728141784668 CE_LOSS :  1.9028842449188232 AUG_LOSS :  34.46992874145508 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.73530578613281 CE_LOSS :  1.3751119375228882 AUG_LOSS :  34.36019515991211 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.61145782470703 CE_LOSS :  0.9999282360076904 AUG_LOSS :  34.61153030395508 ]\n",
      "[BATCH_IDX :  700 LOSS :  35.84706115722656 CE_LOSS :  1.3086153268814087 AUG_LOSS :  34.53844451904297 ]\n",
      "[BATCH_IDX :  720 LOSS :  35.98983383178711 CE_LOSS :  1.5376993417739868 AUG_LOSS :  34.45213317871094 ]\n",
      "Epoch : 3\n",
      "[BATCH_IDX :  0 LOSS :  35.874107360839844 CE_LOSS :  1.1157817840576172 AUG_LOSS :  34.75832748413086 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.596771240234375 CE_LOSS :  1.4671472311019897 AUG_LOSS :  34.12962341308594 ]\n",
      "[BATCH_IDX :  40 LOSS :  35.55875778198242 CE_LOSS :  1.01467764377594 AUG_LOSS :  34.5440788269043 ]\n",
      "[BATCH_IDX :  60 LOSS :  35.388343811035156 CE_LOSS :  1.707123875617981 AUG_LOSS :  33.68122100830078 ]\n",
      "[BATCH_IDX :  80 LOSS :  35.4874153137207 CE_LOSS :  1.1336555480957031 AUG_LOSS :  34.353759765625 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.658897399902344 CE_LOSS :  1.1756502389907837 AUG_LOSS :  34.483245849609375 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.57866668701172 CE_LOSS :  1.0653207302093506 AUG_LOSS :  34.51334762573242 ]\n",
      "[BATCH_IDX :  140 LOSS :  35.70769500732422 CE_LOSS :  1.2921180725097656 AUG_LOSS :  34.41557693481445 ]\n",
      "[BATCH_IDX :  160 LOSS :  36.01723098754883 CE_LOSS :  1.5019229650497437 AUG_LOSS :  34.51530838012695 ]\n",
      "[BATCH_IDX :  180 LOSS :  36.210426330566406 CE_LOSS :  1.4051052331924438 AUG_LOSS :  34.805320739746094 ]\n",
      "[BATCH_IDX :  200 LOSS :  36.83256912231445 CE_LOSS :  1.6159336566925049 AUG_LOSS :  35.216636657714844 ]\n",
      "[BATCH_IDX :  220 LOSS :  36.052310943603516 CE_LOSS :  1.3641526699066162 AUG_LOSS :  34.68815994262695 ]\n",
      "[BATCH_IDX :  240 LOSS :  36.39408874511719 CE_LOSS :  1.536199927330017 AUG_LOSS :  34.857887268066406 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.63235855102539 CE_LOSS :  1.5827823877334595 AUG_LOSS :  34.04957580566406 ]\n",
      "[BATCH_IDX :  280 LOSS :  36.07499313354492 CE_LOSS :  1.1490551233291626 AUG_LOSS :  34.92593765258789 ]\n",
      "[BATCH_IDX :  300 LOSS :  35.05065155029297 CE_LOSS :  1.157726526260376 AUG_LOSS :  33.89292526245117 ]\n",
      "[BATCH_IDX :  320 LOSS :  34.46928405761719 CE_LOSS :  1.3817750215530396 AUG_LOSS :  33.08750915527344 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.015586853027344 CE_LOSS :  1.1568748950958252 AUG_LOSS :  33.85871124267578 ]\n",
      "[BATCH_IDX :  360 LOSS :  36.197059631347656 CE_LOSS :  1.5264360904693604 AUG_LOSS :  34.670623779296875 ]\n",
      "[BATCH_IDX :  380 LOSS :  36.23075485229492 CE_LOSS :  1.2539124488830566 AUG_LOSS :  34.97684097290039 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.341636657714844 CE_LOSS :  1.356238603591919 AUG_LOSS :  33.98539733886719 ]\n",
      "[BATCH_IDX :  420 LOSS :  36.38396072387695 CE_LOSS :  1.2128053903579712 AUG_LOSS :  35.1711540222168 ]\n",
      "[BATCH_IDX :  440 LOSS :  36.11977767944336 CE_LOSS :  1.55118727684021 AUG_LOSS :  34.5685920715332 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.70363235473633 CE_LOSS :  0.8995198607444763 AUG_LOSS :  34.80411148071289 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.74807357788086 CE_LOSS :  1.068342924118042 AUG_LOSS :  34.67972946166992 ]\n",
      "[BATCH_IDX :  500 LOSS :  36.06233596801758 CE_LOSS :  1.4897053241729736 AUG_LOSS :  34.5726318359375 ]\n",
      "[BATCH_IDX :  520 LOSS :  36.03556823730469 CE_LOSS :  1.5768076181411743 AUG_LOSS :  34.45875930786133 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.07222366333008 CE_LOSS :  1.0533677339553833 AUG_LOSS :  34.018856048583984 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.67571258544922 CE_LOSS :  1.3184590339660645 AUG_LOSS :  34.35725402832031 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.28437042236328 CE_LOSS :  1.3413574695587158 AUG_LOSS :  33.94301223754883 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.76249313354492 CE_LOSS :  1.3125473260879517 AUG_LOSS :  34.449947357177734 ]\n",
      "[BATCH_IDX :  620 LOSS :  34.84855651855469 CE_LOSS :  1.0416935682296753 AUG_LOSS :  33.806861877441406 ]\n",
      "[BATCH_IDX :  640 LOSS :  35.37263870239258 CE_LOSS :  1.2620587348937988 AUG_LOSS :  34.11058044433594 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.52206802368164 CE_LOSS :  1.394045352935791 AUG_LOSS :  34.128021240234375 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.98212432861328 CE_LOSS :  1.2004145383834839 AUG_LOSS :  34.78171157836914 ]\n",
      "[BATCH_IDX :  700 LOSS :  36.16368103027344 CE_LOSS :  1.4751431941986084 AUG_LOSS :  34.68853759765625 ]\n",
      "[BATCH_IDX :  720 LOSS :  36.277706146240234 CE_LOSS :  1.4222315549850464 AUG_LOSS :  34.85547637939453 ]\n",
      "Epoch : 4\n",
      "[BATCH_IDX :  0 LOSS :  35.011871337890625 CE_LOSS :  1.415428638458252 AUG_LOSS :  33.59644317626953 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.98037338256836 CE_LOSS :  1.5362392663955688 AUG_LOSS :  34.44413375854492 ]\n",
      "[BATCH_IDX :  40 LOSS :  35.786617279052734 CE_LOSS :  1.3210570812225342 AUG_LOSS :  34.46556091308594 ]\n",
      "[BATCH_IDX :  60 LOSS :  35.680320739746094 CE_LOSS :  0.9905989766120911 AUG_LOSS :  34.689720153808594 ]\n",
      "[BATCH_IDX :  80 LOSS :  36.008296966552734 CE_LOSS :  1.2718844413757324 AUG_LOSS :  34.736412048339844 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.76881790161133 CE_LOSS :  1.1092877388000488 AUG_LOSS :  34.65953063964844 ]\n",
      "[BATCH_IDX :  120 LOSS :  36.05827331542969 CE_LOSS :  1.31135094165802 AUG_LOSS :  34.74692153930664 ]\n",
      "[BATCH_IDX :  140 LOSS :  36.334205627441406 CE_LOSS :  1.7745025157928467 AUG_LOSS :  34.5597038269043 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  160 LOSS :  35.005889892578125 CE_LOSS :  1.111380934715271 AUG_LOSS :  33.894508361816406 ]\n",
      "[BATCH_IDX :  180 LOSS :  34.993499755859375 CE_LOSS :  1.1406716108322144 AUG_LOSS :  33.85282897949219 ]\n",
      "[BATCH_IDX :  200 LOSS :  35.44406509399414 CE_LOSS :  1.2645494937896729 AUG_LOSS :  34.17951583862305 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.9193229675293 CE_LOSS :  1.5053240060806274 AUG_LOSS :  34.413997650146484 ]\n",
      "[BATCH_IDX :  240 LOSS :  35.50479507446289 CE_LOSS :  1.4339512586593628 AUG_LOSS :  34.07084274291992 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.740478515625 CE_LOSS :  1.2723681926727295 AUG_LOSS :  34.468109130859375 ]\n",
      "[BATCH_IDX :  280 LOSS :  35.556121826171875 CE_LOSS :  1.3998572826385498 AUG_LOSS :  34.15626525878906 ]\n",
      "[BATCH_IDX :  300 LOSS :  35.642757415771484 CE_LOSS :  0.9844444990158081 AUG_LOSS :  34.6583137512207 ]\n",
      "[BATCH_IDX :  320 LOSS :  34.93177795410156 CE_LOSS :  1.281515121459961 AUG_LOSS :  33.65026092529297 ]\n",
      "[BATCH_IDX :  340 LOSS :  34.962608337402344 CE_LOSS :  1.1327495574951172 AUG_LOSS :  33.829856872558594 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.35252380371094 CE_LOSS :  1.3164446353912354 AUG_LOSS :  34.03607940673828 ]\n",
      "[BATCH_IDX :  380 LOSS :  36.180503845214844 CE_LOSS :  1.586554765701294 AUG_LOSS :  34.59394836425781 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.51470947265625 CE_LOSS :  1.235437035560608 AUG_LOSS :  34.279273986816406 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.68635177612305 CE_LOSS :  1.3748081922531128 AUG_LOSS :  34.31154251098633 ]\n",
      "[BATCH_IDX :  440 LOSS :  35.37961959838867 CE_LOSS :  1.2106757164001465 AUG_LOSS :  34.1689453125 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.39350891113281 CE_LOSS :  1.2166101932525635 AUG_LOSS :  34.17689895629883 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.958072662353516 CE_LOSS :  1.098685383796692 AUG_LOSS :  34.8593864440918 ]\n",
      "[BATCH_IDX :  500 LOSS :  36.22480010986328 CE_LOSS :  1.2623971700668335 AUG_LOSS :  34.96240234375 ]\n",
      "[BATCH_IDX :  520 LOSS :  36.21820831298828 CE_LOSS :  1.5108418464660645 AUG_LOSS :  34.707366943359375 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.756595611572266 CE_LOSS :  0.8699315786361694 AUG_LOSS :  34.88666534423828 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.55959701538086 CE_LOSS :  1.094360113143921 AUG_LOSS :  34.46523666381836 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.69999694824219 CE_LOSS :  1.491895318031311 AUG_LOSS :  34.20810317993164 ]\n",
      "[BATCH_IDX :  600 LOSS :  36.80137252807617 CE_LOSS :  1.2840406894683838 AUG_LOSS :  35.517330169677734 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.60383987426758 CE_LOSS :  1.5614689588546753 AUG_LOSS :  34.0423698425293 ]\n",
      "[BATCH_IDX :  640 LOSS :  35.73163986206055 CE_LOSS :  0.8747755289077759 AUG_LOSS :  34.85686492919922 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.76100158691406 CE_LOSS :  1.0829987525939941 AUG_LOSS :  34.678001403808594 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.409446716308594 CE_LOSS :  1.5014989376068115 AUG_LOSS :  33.9079475402832 ]\n",
      "[BATCH_IDX :  700 LOSS :  35.98221206665039 CE_LOSS :  1.4006685018539429 AUG_LOSS :  34.58154296875 ]\n",
      "[BATCH_IDX :  720 LOSS :  34.69179153442383 CE_LOSS :  1.3675137758255005 AUG_LOSS :  33.324275970458984 ]\n",
      "Epoch : 5\n",
      "[BATCH_IDX :  0 LOSS :  35.6849250793457 CE_LOSS :  1.4611510038375854 AUG_LOSS :  34.22377395629883 ]\n",
      "[BATCH_IDX :  20 LOSS :  34.82997512817383 CE_LOSS :  1.2806276082992554 AUG_LOSS :  33.549346923828125 ]\n",
      "[BATCH_IDX :  40 LOSS :  35.05535125732422 CE_LOSS :  1.2113096714019775 AUG_LOSS :  33.84403991699219 ]\n",
      "[BATCH_IDX :  60 LOSS :  35.506370544433594 CE_LOSS :  1.0960595607757568 AUG_LOSS :  34.41031265258789 ]\n",
      "[BATCH_IDX :  80 LOSS :  36.37482833862305 CE_LOSS :  1.4485206604003906 AUG_LOSS :  34.926307678222656 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.28025436401367 CE_LOSS :  1.0731879472732544 AUG_LOSS :  34.20706558227539 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.63986587524414 CE_LOSS :  1.0601286888122559 AUG_LOSS :  34.57973861694336 ]\n",
      "[BATCH_IDX :  140 LOSS :  36.07716369628906 CE_LOSS :  1.3098307847976685 AUG_LOSS :  34.767333984375 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.64137649536133 CE_LOSS :  1.259290099143982 AUG_LOSS :  34.38208770751953 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.70414352416992 CE_LOSS :  1.1575596332550049 AUG_LOSS :  34.54658508300781 ]\n",
      "[BATCH_IDX :  200 LOSS :  36.44501876831055 CE_LOSS :  1.2648106813430786 AUG_LOSS :  35.180206298828125 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.18036651611328 CE_LOSS :  0.9303399920463562 AUG_LOSS :  34.25002670288086 ]\n",
      "[BATCH_IDX :  240 LOSS :  35.21121597290039 CE_LOSS :  1.240116000175476 AUG_LOSS :  33.971099853515625 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.46096420288086 CE_LOSS :  1.287984013557434 AUG_LOSS :  34.17298126220703 ]\n",
      "[BATCH_IDX :  280 LOSS :  35.13017654418945 CE_LOSS :  1.2938157320022583 AUG_LOSS :  33.836360931396484 ]\n",
      "[BATCH_IDX :  300 LOSS :  36.872222900390625 CE_LOSS :  1.7376670837402344 AUG_LOSS :  35.13455581665039 ]\n",
      "[BATCH_IDX :  320 LOSS :  35.97256851196289 CE_LOSS :  1.4628819227218628 AUG_LOSS :  34.50968551635742 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.604740142822266 CE_LOSS :  1.5289157629013062 AUG_LOSS :  34.07582473754883 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.405887603759766 CE_LOSS :  1.4106484651565552 AUG_LOSS :  33.9952392578125 ]\n",
      "[BATCH_IDX :  380 LOSS :  35.57841110229492 CE_LOSS :  1.0639094114303589 AUG_LOSS :  34.514503479003906 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.47404861450195 CE_LOSS :  1.2065985202789307 AUG_LOSS :  34.26744842529297 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.23923873901367 CE_LOSS :  1.0600248575210571 AUG_LOSS :  34.17921447753906 ]\n",
      "[BATCH_IDX :  440 LOSS :  35.432861328125 CE_LOSS :  0.8232914209365845 AUG_LOSS :  34.60956954956055 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.447975158691406 CE_LOSS :  1.3621656894683838 AUG_LOSS :  34.08580780029297 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.932308197021484 CE_LOSS :  1.2377005815505981 AUG_LOSS :  34.69460678100586 ]\n",
      "[BATCH_IDX :  500 LOSS :  35.219810485839844 CE_LOSS :  1.0774929523468018 AUG_LOSS :  34.14231872558594 ]\n",
      "[BATCH_IDX :  520 LOSS :  35.847599029541016 CE_LOSS :  1.0507127046585083 AUG_LOSS :  34.7968864440918 ]\n",
      "[BATCH_IDX :  540 LOSS :  36.285892486572266 CE_LOSS :  1.4142290353775024 AUG_LOSS :  34.87166213989258 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.68168640136719 CE_LOSS :  1.3657987117767334 AUG_LOSS :  34.315887451171875 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.97293472290039 CE_LOSS :  1.273789644241333 AUG_LOSS :  34.69914627075195 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.79014205932617 CE_LOSS :  1.1811747550964355 AUG_LOSS :  34.60896682739258 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.64286804199219 CE_LOSS :  1.3700958490371704 AUG_LOSS :  34.27277374267578 ]\n",
      "[BATCH_IDX :  640 LOSS :  36.20534896850586 CE_LOSS :  1.416136622428894 AUG_LOSS :  34.78921127319336 ]\n",
      "[BATCH_IDX :  660 LOSS :  34.756412506103516 CE_LOSS :  1.1272056102752686 AUG_LOSS :  33.629207611083984 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.81499481201172 CE_LOSS :  1.3280372619628906 AUG_LOSS :  34.48695755004883 ]\n",
      "[BATCH_IDX :  700 LOSS :  35.155181884765625 CE_LOSS :  1.1720430850982666 AUG_LOSS :  33.98313903808594 ]\n",
      "[BATCH_IDX :  720 LOSS :  35.63654708862305 CE_LOSS :  1.7609143257141113 AUG_LOSS :  33.875633239746094 ]\n",
      "Epoch : 6\n",
      "[BATCH_IDX :  0 LOSS :  35.758270263671875 CE_LOSS :  1.109182357788086 AUG_LOSS :  34.64908981323242 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.37897491455078 CE_LOSS :  1.3060574531555176 AUG_LOSS :  34.07291793823242 ]\n",
      "[BATCH_IDX :  40 LOSS :  35.677459716796875 CE_LOSS :  1.352832555770874 AUG_LOSS :  34.32462692260742 ]\n",
      "[BATCH_IDX :  60 LOSS :  35.692161560058594 CE_LOSS :  1.207565426826477 AUG_LOSS :  34.484596252441406 ]\n",
      "[BATCH_IDX :  80 LOSS :  35.5271110534668 CE_LOSS :  1.3892747163772583 AUG_LOSS :  34.13783645629883 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.45553970336914 CE_LOSS :  1.0784651041030884 AUG_LOSS :  34.3770751953125 ]\n",
      "[BATCH_IDX :  120 LOSS :  34.762149810791016 CE_LOSS :  1.293904423713684 AUG_LOSS :  33.46824645996094 ]\n",
      "[BATCH_IDX :  140 LOSS :  36.00706481933594 CE_LOSS :  1.1371976137161255 AUG_LOSS :  34.86986541748047 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.42976760864258 CE_LOSS :  1.1213382482528687 AUG_LOSS :  34.30842971801758 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.29206466674805 CE_LOSS :  1.1855103969573975 AUG_LOSS :  34.1065559387207 ]\n",
      "[BATCH_IDX :  200 LOSS :  35.30265808105469 CE_LOSS :  1.1614054441452026 AUG_LOSS :  34.14125442504883 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.77457046508789 CE_LOSS :  1.1107014417648315 AUG_LOSS :  34.66386795043945 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  240 LOSS :  35.90045166015625 CE_LOSS :  0.9947369694709778 AUG_LOSS :  34.90571594238281 ]\n",
      "[BATCH_IDX :  260 LOSS :  35.24053192138672 CE_LOSS :  1.1928753852844238 AUG_LOSS :  34.04765701293945 ]\n",
      "[BATCH_IDX :  280 LOSS :  35.26482009887695 CE_LOSS :  1.500867486000061 AUG_LOSS :  33.763954162597656 ]\n",
      "[BATCH_IDX :  300 LOSS :  35.560546875 CE_LOSS :  1.6166983842849731 AUG_LOSS :  33.94384765625 ]\n",
      "[BATCH_IDX :  320 LOSS :  35.836822509765625 CE_LOSS :  1.252665400505066 AUG_LOSS :  34.58415603637695 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.90696716308594 CE_LOSS :  0.8413085341453552 AUG_LOSS :  35.06565856933594 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.87959671020508 CE_LOSS :  1.2604871988296509 AUG_LOSS :  34.619110107421875 ]\n",
      "[BATCH_IDX :  380 LOSS :  35.2229118347168 CE_LOSS :  1.0990946292877197 AUG_LOSS :  34.123817443847656 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.95759963989258 CE_LOSS :  1.1736432313919067 AUG_LOSS :  34.78395462036133 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.475730895996094 CE_LOSS :  1.093191146850586 AUG_LOSS :  34.38254165649414 ]\n",
      "[BATCH_IDX :  440 LOSS :  35.841102600097656 CE_LOSS :  1.3635300397872925 AUG_LOSS :  34.47757339477539 ]\n",
      "[BATCH_IDX :  460 LOSS :  35.81704330444336 CE_LOSS :  1.2565516233444214 AUG_LOSS :  34.56049346923828 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.8354606628418 CE_LOSS :  1.1903374195098877 AUG_LOSS :  34.64512252807617 ]\n",
      "[BATCH_IDX :  500 LOSS :  36.693275451660156 CE_LOSS :  1.0509179830551147 AUG_LOSS :  35.642356872558594 ]\n",
      "[BATCH_IDX :  520 LOSS :  35.92022705078125 CE_LOSS :  1.0742487907409668 AUG_LOSS :  34.845977783203125 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.648536682128906 CE_LOSS :  1.655290126800537 AUG_LOSS :  33.993247985839844 ]\n",
      "[BATCH_IDX :  560 LOSS :  36.07553482055664 CE_LOSS :  1.1284947395324707 AUG_LOSS :  34.94704055786133 ]\n",
      "[BATCH_IDX :  580 LOSS :  35.117530822753906 CE_LOSS :  0.9660231471061707 AUG_LOSS :  34.15150833129883 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.91278839111328 CE_LOSS :  1.062150239944458 AUG_LOSS :  34.85063934326172 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.71647644042969 CE_LOSS :  1.2286109924316406 AUG_LOSS :  34.48786544799805 ]\n",
      "[BATCH_IDX :  640 LOSS :  36.07744216918945 CE_LOSS :  1.2496486902236938 AUG_LOSS :  34.82779312133789 ]\n",
      "[BATCH_IDX :  660 LOSS :  36.879295349121094 CE_LOSS :  1.3726598024368286 AUG_LOSS :  35.50663375854492 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.60810470581055 CE_LOSS :  1.415162444114685 AUG_LOSS :  34.19294357299805 ]\n",
      "[BATCH_IDX :  700 LOSS :  36.12450408935547 CE_LOSS :  1.0784164667129517 AUG_LOSS :  35.04608917236328 ]\n",
      "[BATCH_IDX :  720 LOSS :  35.55613708496094 CE_LOSS :  1.1014983654022217 AUG_LOSS :  34.45463943481445 ]\n",
      "Epoch : 7\n",
      "[BATCH_IDX :  0 LOSS :  35.642974853515625 CE_LOSS :  1.4307883977890015 AUG_LOSS :  34.21218490600586 ]\n",
      "[BATCH_IDX :  20 LOSS :  35.94243240356445 CE_LOSS :  0.8241916298866272 AUG_LOSS :  35.11824035644531 ]\n",
      "[BATCH_IDX :  40 LOSS :  36.01527404785156 CE_LOSS :  1.2827389240264893 AUG_LOSS :  34.73253631591797 ]\n",
      "[BATCH_IDX :  60 LOSS :  36.799015045166016 CE_LOSS :  2.0321500301361084 AUG_LOSS :  34.76686477661133 ]\n",
      "[BATCH_IDX :  80 LOSS :  35.844364166259766 CE_LOSS :  1.2935513257980347 AUG_LOSS :  34.550811767578125 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.82367706298828 CE_LOSS :  1.1387406587600708 AUG_LOSS :  34.6849365234375 ]\n",
      "[BATCH_IDX :  120 LOSS :  35.1934928894043 CE_LOSS :  1.3317571878433228 AUG_LOSS :  33.86173629760742 ]\n",
      "[BATCH_IDX :  140 LOSS :  35.4540901184082 CE_LOSS :  1.0260816812515259 AUG_LOSS :  34.428009033203125 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.83572006225586 CE_LOSS :  1.1631782054901123 AUG_LOSS :  34.672542572021484 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.8760986328125 CE_LOSS :  1.5357154607772827 AUG_LOSS :  34.34038162231445 ]\n",
      "[BATCH_IDX :  200 LOSS :  36.17233657836914 CE_LOSS :  1.2111886739730835 AUG_LOSS :  34.96114730834961 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.979576110839844 CE_LOSS :  1.235732913017273 AUG_LOSS :  34.74384307861328 ]\n",
      "[BATCH_IDX :  240 LOSS :  35.898216247558594 CE_LOSS :  1.1878702640533447 AUG_LOSS :  34.71034622192383 ]\n",
      "[BATCH_IDX :  260 LOSS :  34.877593994140625 CE_LOSS :  1.2690154314041138 AUG_LOSS :  33.608577728271484 ]\n",
      "[BATCH_IDX :  280 LOSS :  36.03142547607422 CE_LOSS :  1.2705494165420532 AUG_LOSS :  34.7608757019043 ]\n",
      "[BATCH_IDX :  300 LOSS :  35.4983024597168 CE_LOSS :  1.019787073135376 AUG_LOSS :  34.478515625 ]\n",
      "[BATCH_IDX :  320 LOSS :  35.393367767333984 CE_LOSS :  1.1271470785140991 AUG_LOSS :  34.26622009277344 ]\n",
      "[BATCH_IDX :  340 LOSS :  35.50639343261719 CE_LOSS :  1.0114452838897705 AUG_LOSS :  34.49494934082031 ]\n",
      "[BATCH_IDX :  360 LOSS :  35.7140998840332 CE_LOSS :  1.125238060951233 AUG_LOSS :  34.588863372802734 ]\n",
      "[BATCH_IDX :  380 LOSS :  35.590919494628906 CE_LOSS :  1.356414794921875 AUG_LOSS :  34.23450469970703 ]\n",
      "[BATCH_IDX :  400 LOSS :  35.827571868896484 CE_LOSS :  1.168089747428894 AUG_LOSS :  34.659481048583984 ]\n",
      "[BATCH_IDX :  420 LOSS :  35.95157241821289 CE_LOSS :  0.978198230266571 AUG_LOSS :  34.97337341308594 ]\n",
      "[BATCH_IDX :  440 LOSS :  34.606021881103516 CE_LOSS :  0.8305476903915405 AUG_LOSS :  33.775474548339844 ]\n",
      "[BATCH_IDX :  460 LOSS :  36.19676971435547 CE_LOSS :  1.359082818031311 AUG_LOSS :  34.83768844604492 ]\n",
      "[BATCH_IDX :  480 LOSS :  35.62085723876953 CE_LOSS :  1.4056767225265503 AUG_LOSS :  34.215179443359375 ]\n",
      "[BATCH_IDX :  500 LOSS :  35.5183219909668 CE_LOSS :  1.574360728263855 AUG_LOSS :  33.94396209716797 ]\n",
      "[BATCH_IDX :  520 LOSS :  35.953643798828125 CE_LOSS :  1.1791332960128784 AUG_LOSS :  34.77450942993164 ]\n",
      "[BATCH_IDX :  540 LOSS :  35.58762741088867 CE_LOSS :  1.4677802324295044 AUG_LOSS :  34.11984634399414 ]\n",
      "[BATCH_IDX :  560 LOSS :  35.49216842651367 CE_LOSS :  1.5191763639450073 AUG_LOSS :  33.972991943359375 ]\n",
      "[BATCH_IDX :  580 LOSS :  36.003273010253906 CE_LOSS :  1.202745795249939 AUG_LOSS :  34.8005256652832 ]\n",
      "[BATCH_IDX :  600 LOSS :  35.34576416015625 CE_LOSS :  1.0703386068344116 AUG_LOSS :  34.27542495727539 ]\n",
      "[BATCH_IDX :  620 LOSS :  35.71583938598633 CE_LOSS :  1.4341747760772705 AUG_LOSS :  34.28166580200195 ]\n",
      "[BATCH_IDX :  640 LOSS :  34.80418395996094 CE_LOSS :  1.2307361364364624 AUG_LOSS :  33.573448181152344 ]\n",
      "[BATCH_IDX :  660 LOSS :  35.143550872802734 CE_LOSS :  1.1302664279937744 AUG_LOSS :  34.013282775878906 ]\n",
      "[BATCH_IDX :  680 LOSS :  35.18688201904297 CE_LOSS :  0.8217017650604248 AUG_LOSS :  34.36518096923828 ]\n",
      "[BATCH_IDX :  700 LOSS :  35.489871978759766 CE_LOSS :  1.1741547584533691 AUG_LOSS :  34.31571578979492 ]\n",
      "[BATCH_IDX :  720 LOSS :  36.348228454589844 CE_LOSS :  1.611893892288208 AUG_LOSS :  34.73633575439453 ]\n",
      "Epoch : 8\n",
      "[BATCH_IDX :  0 LOSS :  35.95220184326172 CE_LOSS :  1.0427055358886719 AUG_LOSS :  34.90949630737305 ]\n",
      "[BATCH_IDX :  20 LOSS :  36.51988220214844 CE_LOSS :  1.881104588508606 AUG_LOSS :  34.63877868652344 ]\n",
      "[BATCH_IDX :  40 LOSS :  36.4552116394043 CE_LOSS :  1.2769553661346436 AUG_LOSS :  35.17825698852539 ]\n",
      "[BATCH_IDX :  60 LOSS :  35.63041305541992 CE_LOSS :  1.0783770084381104 AUG_LOSS :  34.55203628540039 ]\n",
      "[BATCH_IDX :  80 LOSS :  36.155609130859375 CE_LOSS :  1.3537209033966064 AUG_LOSS :  34.80188751220703 ]\n",
      "[BATCH_IDX :  100 LOSS :  35.919376373291016 CE_LOSS :  1.215598225593567 AUG_LOSS :  34.70377731323242 ]\n",
      "[BATCH_IDX :  120 LOSS :  34.983306884765625 CE_LOSS :  0.838697612285614 AUG_LOSS :  34.14460754394531 ]\n",
      "[BATCH_IDX :  140 LOSS :  34.478031158447266 CE_LOSS :  0.8202565312385559 AUG_LOSS :  33.65777587890625 ]\n",
      "[BATCH_IDX :  160 LOSS :  35.727745056152344 CE_LOSS :  1.1494234800338745 AUG_LOSS :  34.57832336425781 ]\n",
      "[BATCH_IDX :  180 LOSS :  35.698829650878906 CE_LOSS :  1.2087372541427612 AUG_LOSS :  34.49009323120117 ]\n",
      "[BATCH_IDX :  200 LOSS :  35.14117431640625 CE_LOSS :  1.1037708520889282 AUG_LOSS :  34.03740310668945 ]\n",
      "[BATCH_IDX :  220 LOSS :  35.306846618652344 CE_LOSS :  1.344880223274231 AUG_LOSS :  33.96196746826172 ]\n",
      "[BATCH_IDX :  240 LOSS :  36.51683807373047 CE_LOSS :  1.4028124809265137 AUG_LOSS :  35.1140251159668 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1096/1541093274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[BATCH_IDX : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LOSS : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CE_LOSS : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mce_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AUG_LOSS : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maug_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"]\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "    print(\"Epoch : %d\"% (epoch))\n",
    "    \n",
    "    for batch_idx, (inputs1, inputs2, indexes) in enumerate(trainloader):\n",
    "        inputs1, inputs2, indexes = inputs1.cuda(), inputs2.cuda(), indexes.cuda()           \n",
    "        batch_size = inputs1.shape[0]\n",
    "        labels = p_label[indexes].cuda()\n",
    "        inputs = torch.cat([inputs1, inputs2])\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.reshape(-1,1280)\n",
    "        outputs1 = outputs[:batch_size]\n",
    "        outputs2 = outputs[batch_size:]\n",
    "        outputs3 = fc(outputs1)\n",
    "        ce_loss = criterion(outputs3, labels) \n",
    "        aug_loss = criterion2(outputs1, outputs2) / 60\n",
    "#         aug_loss = criterion2(outputs1, outputs2) / 10\n",
    "        loss = ce_loss + aug_loss\n",
    "        optimizer.zero_grad()\n",
    "        optimizer1.zero_grad()\n",
    "        ce_loss.backward()\n",
    "#         aug_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\"[BATCH_IDX : \", batch_idx, \"LOSS : \",loss.item(), \"CE_LOSS : \",ce_loss.item(),\"AUG_LOSS : \",aug_loss.item(),\"]\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/haoying/res_zl12_effnet_v4')\n",
    "torch.save(model, 'rural.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city\n",
    "clusterset = GPSDataset('/home/haoying/res_zl12_effnet_v4/nightlights_labeled2.csv', '/home/haoying/data_zl12/', cluster_transform)\n",
    "trainset = GPSDataset('/home/haoying/res_zl12_effnet_v4/nightlights_labeled2.csv', '/home/haoying/data_zl12/', train_transform1, train_transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/haoying/res_zl12_effnet_v4/res_pretrained.pt')\n",
    "model._fc = nn.Identity()\n",
    "model._swish = nn.Identity()\n",
    "# model = nn.Sequential(*(list(model.children())[:-3])) # strips off last linear layer\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9125, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_ = features\n",
    "pca = PCA(n_components = 0.80) \n",
    "pca.fit(X_)\n",
    "reduced_X = pca.transform(X_)\n",
    "reduced_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means loss evolution: [5362.55761719 2958.05908203 2809.74853516 2777.84570312 2739.91455078\n",
      " 2663.68432617 2569.99804688 2534.28881836 2521.49609375 2513.04248047\n",
      " 2507.09472656 2502.73754883 2497.34277344 2492.24169922 2487.96850586\n",
      " 2483.46069336 2476.3112793  2467.15991211 2461.41064453 2458.2668457 ]\n",
      "tensor([3, 3, 3,  ..., 0, 3, 3], device='cuda:0')\n",
      "k-means time: 2 s\n"
     ]
    }
   ],
   "source": [
    "clusterloader = torch.utils.data.DataLoader(clusterset, batch_size=10, shuffle=False, num_workers=0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True, num_workers=0, drop_last = True)\n",
    "deepcluster = Kmeans(5)\n",
    "\n",
    "features = compute_features(clusterloader, model, len(clusterset), 10) \n",
    "clustering_loss, p_label = deepcluster.cluster(features,pca=13)\n",
    "p_label = p_label.tolist()\n",
    "p_label = torch.tensor(p_label).cuda()\n",
    "model.train()\n",
    "\n",
    "fc = nn.Linear(1280, 5)\n",
    "fc.weight.data.normal_(0, 0.01)\n",
    "fc.bias.data.zero_()\n",
    "fc.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "optimizer1 = torch.optim.SGD(fc.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "[BATCH_IDX :  0 LOSS :  24.323280334472656 CE_LOSS :  1.7344690561294556 AUG_LOSS :  22.58881187438965 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.345783233642578 CE_LOSS :  1.2103490829467773 AUG_LOSS :  22.135433197021484 ]\n",
      "[BATCH_IDX :  40 LOSS :  22.673900604248047 CE_LOSS :  1.2271826267242432 AUG_LOSS :  21.446718215942383 ]\n",
      "[BATCH_IDX :  60 LOSS :  22.78711700439453 CE_LOSS :  1.3806514739990234 AUG_LOSS :  21.406465530395508 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.44489097595215 CE_LOSS :  1.2270513772964478 AUG_LOSS :  22.21784019470215 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.939218521118164 CE_LOSS :  1.5294115543365479 AUG_LOSS :  22.409807205200195 ]\n",
      "[BATCH_IDX :  120 LOSS :  23.112979888916016 CE_LOSS :  0.8744834661483765 AUG_LOSS :  22.238496780395508 ]\n",
      "[BATCH_IDX :  140 LOSS :  22.87371253967285 CE_LOSS :  0.43530821800231934 AUG_LOSS :  22.438404083251953 ]\n",
      "[BATCH_IDX :  160 LOSS :  22.936431884765625 CE_LOSS :  1.0777267217636108 AUG_LOSS :  21.858705520629883 ]\n",
      "[BATCH_IDX :  180 LOSS :  24.65859603881836 CE_LOSS :  2.245586633682251 AUG_LOSS :  22.413009643554688 ]\n",
      "[BATCH_IDX :  200 LOSS :  23.33818817138672 CE_LOSS :  0.8536126017570496 AUG_LOSS :  22.484575271606445 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.973323822021484 CE_LOSS :  0.7473905682563782 AUG_LOSS :  23.225933074951172 ]\n",
      "[BATCH_IDX :  240 LOSS :  23.70880126953125 CE_LOSS :  1.181542158126831 AUG_LOSS :  22.527259826660156 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.247549057006836 CE_LOSS :  0.6854280233383179 AUG_LOSS :  22.56212043762207 ]\n",
      "[BATCH_IDX :  280 LOSS :  23.537641525268555 CE_LOSS :  1.5713839530944824 AUG_LOSS :  21.966257095336914 ]\n",
      "[BATCH_IDX :  300 LOSS :  24.85442352294922 CE_LOSS :  1.5822250843048096 AUG_LOSS :  23.272197723388672 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.84922218322754 CE_LOSS :  1.634608507156372 AUG_LOSS :  22.21461296081543 ]\n",
      "[BATCH_IDX :  340 LOSS :  22.593280792236328 CE_LOSS :  0.7388875484466553 AUG_LOSS :  21.854393005371094 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.87607765197754 CE_LOSS :  1.8313506841659546 AUG_LOSS :  22.044727325439453 ]\n",
      "[BATCH_IDX :  380 LOSS :  22.781356811523438 CE_LOSS :  0.8006596565246582 AUG_LOSS :  21.980697631835938 ]\n",
      "[BATCH_IDX :  400 LOSS :  25.140350341796875 CE_LOSS :  1.7336924076080322 AUG_LOSS :  23.406658172607422 ]\n",
      "[BATCH_IDX :  420 LOSS :  22.087411880493164 CE_LOSS :  0.2161308228969574 AUG_LOSS :  21.871280670166016 ]\n",
      "[BATCH_IDX :  440 LOSS :  22.942401885986328 CE_LOSS :  1.542550802230835 AUG_LOSS :  21.399850845336914 ]\n",
      "[BATCH_IDX :  460 LOSS :  22.630125045776367 CE_LOSS :  0.4673677086830139 AUG_LOSS :  22.162757873535156 ]\n",
      "[BATCH_IDX :  480 LOSS :  24.304271697998047 CE_LOSS :  1.202703595161438 AUG_LOSS :  23.1015682220459 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.881473541259766 CE_LOSS :  1.745410680770874 AUG_LOSS :  22.136062622070312 ]\n",
      "[BATCH_IDX :  520 LOSS :  24.327661514282227 CE_LOSS :  1.5771195888519287 AUG_LOSS :  22.75054168701172 ]\n",
      "[BATCH_IDX :  540 LOSS :  22.640758514404297 CE_LOSS :  0.7407796382904053 AUG_LOSS :  21.899978637695312 ]\n",
      "[BATCH_IDX :  560 LOSS :  25.16280746459961 CE_LOSS :  2.6030941009521484 AUG_LOSS :  22.55971336364746 ]\n",
      "[BATCH_IDX :  580 LOSS :  22.370798110961914 CE_LOSS :  0.6941494941711426 AUG_LOSS :  21.67664909362793 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.416900634765625 CE_LOSS :  0.719151496887207 AUG_LOSS :  22.6977481842041 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.387590408325195 CE_LOSS :  0.9256361722946167 AUG_LOSS :  22.46195411682129 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.250289916992188 CE_LOSS :  1.1317451000213623 AUG_LOSS :  22.118545532226562 ]\n",
      "[BATCH_IDX :  660 LOSS :  22.003904342651367 CE_LOSS :  0.7291641235351562 AUG_LOSS :  21.27474021911621 ]\n",
      "[BATCH_IDX :  680 LOSS :  22.558244705200195 CE_LOSS :  0.9128564596176147 AUG_LOSS :  21.645387649536133 ]\n",
      "[BATCH_IDX :  700 LOSS :  23.9564151763916 CE_LOSS :  1.0498149394989014 AUG_LOSS :  22.906600952148438 ]\n",
      "[BATCH_IDX :  720 LOSS :  23.410324096679688 CE_LOSS :  1.6666715145111084 AUG_LOSS :  21.74365234375 ]\n",
      "[BATCH_IDX :  740 LOSS :  23.420507431030273 CE_LOSS :  0.7389541864395142 AUG_LOSS :  22.68155288696289 ]\n",
      "[BATCH_IDX :  760 LOSS :  24.079755783081055 CE_LOSS :  2.0036990642547607 AUG_LOSS :  22.07605743408203 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.39143943786621 CE_LOSS :  0.8987396359443665 AUG_LOSS :  22.492700576782227 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.24232292175293 CE_LOSS :  1.017472505569458 AUG_LOSS :  22.224849700927734 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.868316650390625 CE_LOSS :  2.1442184448242188 AUG_LOSS :  21.724098205566406 ]\n",
      "[BATCH_IDX :  840 LOSS :  24.051868438720703 CE_LOSS :  2.0122077465057373 AUG_LOSS :  22.039661407470703 ]\n",
      "[BATCH_IDX :  860 LOSS :  23.295385360717773 CE_LOSS :  0.4482084810733795 AUG_LOSS :  22.847177505493164 ]\n",
      "[BATCH_IDX :  880 LOSS :  23.740955352783203 CE_LOSS :  1.0380620956420898 AUG_LOSS :  22.70289421081543 ]\n",
      "[BATCH_IDX :  900 LOSS :  24.363079071044922 CE_LOSS :  1.6084487438201904 AUG_LOSS :  22.75463104248047 ]\n",
      "Epoch : 1\n",
      "[BATCH_IDX :  0 LOSS :  23.698183059692383 CE_LOSS :  1.229244589805603 AUG_LOSS :  22.46893882751465 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.247600555419922 CE_LOSS :  0.7673115134239197 AUG_LOSS :  22.480289459228516 ]\n",
      "[BATCH_IDX :  40 LOSS :  23.032367706298828 CE_LOSS :  0.6159542798995972 AUG_LOSS :  22.416414260864258 ]\n",
      "[BATCH_IDX :  60 LOSS :  22.434429168701172 CE_LOSS :  0.803618311882019 AUG_LOSS :  21.63081169128418 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.313491821289062 CE_LOSS :  0.9215396642684937 AUG_LOSS :  22.391952514648438 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.11821937561035 CE_LOSS :  1.0509893894195557 AUG_LOSS :  22.067230224609375 ]\n",
      "[BATCH_IDX :  120 LOSS :  23.148727416992188 CE_LOSS :  0.8177986145019531 AUG_LOSS :  22.330928802490234 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.10948371887207 CE_LOSS :  1.286899447441101 AUG_LOSS :  21.82258415222168 ]\n",
      "[BATCH_IDX :  160 LOSS :  24.328840255737305 CE_LOSS :  1.6186929941177368 AUG_LOSS :  22.710147857666016 ]\n",
      "[BATCH_IDX :  180 LOSS :  23.12237548828125 CE_LOSS :  1.328277349472046 AUG_LOSS :  21.794097900390625 ]\n",
      "[BATCH_IDX :  200 LOSS :  23.5579833984375 CE_LOSS :  1.360687494277954 AUG_LOSS :  22.197296142578125 ]\n",
      "[BATCH_IDX :  220 LOSS :  24.879150390625 CE_LOSS :  1.8264665603637695 AUG_LOSS :  23.052682876586914 ]\n",
      "[BATCH_IDX :  240 LOSS :  25.534189224243164 CE_LOSS :  2.0778555870056152 AUG_LOSS :  23.45633316040039 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.267200469970703 CE_LOSS :  0.9691528081893921 AUG_LOSS :  22.29804801940918 ]\n",
      "[BATCH_IDX :  280 LOSS :  22.712093353271484 CE_LOSS :  0.5778511166572571 AUG_LOSS :  22.13424301147461 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.21259307861328 CE_LOSS :  0.7559504508972168 AUG_LOSS :  22.456642150878906 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.478193283081055 CE_LOSS :  1.7270952463150024 AUG_LOSS :  21.7510986328125 ]\n",
      "[BATCH_IDX :  340 LOSS :  24.285520553588867 CE_LOSS :  1.5187627077102661 AUG_LOSS :  22.76675796508789 ]\n",
      "[BATCH_IDX :  360 LOSS :  24.02652359008789 CE_LOSS :  1.758042335510254 AUG_LOSS :  22.26848030090332 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.510629653930664 CE_LOSS :  1.1937339305877686 AUG_LOSS :  22.316896438598633 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.95224380493164 CE_LOSS :  1.4194109439849854 AUG_LOSS :  22.532833099365234 ]\n",
      "[BATCH_IDX :  420 LOSS :  24.36185646057129 CE_LOSS :  1.5874803066253662 AUG_LOSS :  22.774375915527344 ]\n",
      "[BATCH_IDX :  440 LOSS :  23.411712646484375 CE_LOSS :  0.7524258494377136 AUG_LOSS :  22.659286499023438 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.364261627197266 CE_LOSS :  1.010707139968872 AUG_LOSS :  22.353553771972656 ]\n",
      "[BATCH_IDX :  480 LOSS :  24.07845687866211 CE_LOSS :  0.8336693048477173 AUG_LOSS :  23.244787216186523 ]\n",
      "[BATCH_IDX :  500 LOSS :  22.533222198486328 CE_LOSS :  0.7020046710968018 AUG_LOSS :  21.83121681213379 ]\n",
      "[BATCH_IDX :  520 LOSS :  23.70815086364746 CE_LOSS :  1.2347561120986938 AUG_LOSS :  22.4733943939209 ]\n",
      "[BATCH_IDX :  540 LOSS :  24.723602294921875 CE_LOSS :  2.255143404006958 AUG_LOSS :  22.46845817565918 ]\n",
      "[BATCH_IDX :  560 LOSS :  22.30840301513672 CE_LOSS :  0.7011919021606445 AUG_LOSS :  21.60721206665039 ]\n",
      "[BATCH_IDX :  580 LOSS :  23.72966766357422 CE_LOSS :  1.1790493726730347 AUG_LOSS :  22.55061912536621 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.92982292175293 CE_LOSS :  1.7337639331817627 AUG_LOSS :  22.19605827331543 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  620 LOSS :  22.875547409057617 CE_LOSS :  0.6843886375427246 AUG_LOSS :  22.191158294677734 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.554750442504883 CE_LOSS :  1.3607271909713745 AUG_LOSS :  22.19402313232422 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.591798782348633 CE_LOSS :  0.6625816226005554 AUG_LOSS :  22.929216384887695 ]\n",
      "[BATCH_IDX :  680 LOSS :  23.172367095947266 CE_LOSS :  0.43870919942855835 AUG_LOSS :  22.733657836914062 ]\n",
      "[BATCH_IDX :  700 LOSS :  24.36164093017578 CE_LOSS :  1.8599668741226196 AUG_LOSS :  22.50167465209961 ]\n",
      "[BATCH_IDX :  720 LOSS :  23.350482940673828 CE_LOSS :  0.7557963132858276 AUG_LOSS :  22.59468650817871 ]\n",
      "[BATCH_IDX :  740 LOSS :  22.44379997253418 CE_LOSS :  0.5365921854972839 AUG_LOSS :  21.907207489013672 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.590354919433594 CE_LOSS :  0.6751765012741089 AUG_LOSS :  22.915178298950195 ]\n",
      "[BATCH_IDX :  780 LOSS :  22.909465789794922 CE_LOSS :  1.5998197793960571 AUG_LOSS :  21.309646606445312 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.7614803314209 CE_LOSS :  0.8413127660751343 AUG_LOSS :  22.920167922973633 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.47146224975586 CE_LOSS :  1.2748136520385742 AUG_LOSS :  22.19664764404297 ]\n",
      "[BATCH_IDX :  840 LOSS :  23.1595516204834 CE_LOSS :  0.6678013205528259 AUG_LOSS :  22.491750717163086 ]\n",
      "[BATCH_IDX :  860 LOSS :  23.700191497802734 CE_LOSS :  1.9070549011230469 AUG_LOSS :  21.793136596679688 ]\n",
      "[BATCH_IDX :  880 LOSS :  23.485326766967773 CE_LOSS :  1.2145936489105225 AUG_LOSS :  22.270732879638672 ]\n",
      "[BATCH_IDX :  900 LOSS :  21.97524070739746 CE_LOSS :  0.5460540056228638 AUG_LOSS :  21.42918586730957 ]\n",
      "Epoch : 2\n",
      "[BATCH_IDX :  0 LOSS :  22.53493881225586 CE_LOSS :  0.9084113240242004 AUG_LOSS :  21.626527786254883 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.561077117919922 CE_LOSS :  0.9942415356636047 AUG_LOSS :  22.566835403442383 ]\n",
      "[BATCH_IDX :  40 LOSS :  23.265169143676758 CE_LOSS :  0.7568433284759521 AUG_LOSS :  22.508325576782227 ]\n",
      "[BATCH_IDX :  60 LOSS :  22.533668518066406 CE_LOSS :  0.5893722772598267 AUG_LOSS :  21.94429588317871 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.756444931030273 CE_LOSS :  1.217326045036316 AUG_LOSS :  22.539119720458984 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.59947395324707 CE_LOSS :  1.109580397605896 AUG_LOSS :  22.489892959594727 ]\n",
      "[BATCH_IDX :  120 LOSS :  23.289995193481445 CE_LOSS :  1.0381265878677368 AUG_LOSS :  22.251869201660156 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.02285385131836 CE_LOSS :  0.44468384981155396 AUG_LOSS :  22.578170776367188 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.126667022705078 CE_LOSS :  1.078920841217041 AUG_LOSS :  22.047746658325195 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.331899642944336 CE_LOSS :  0.5012795329093933 AUG_LOSS :  21.83061981201172 ]\n",
      "[BATCH_IDX :  200 LOSS :  22.871444702148438 CE_LOSS :  1.025024175643921 AUG_LOSS :  21.846420288085938 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.12903594970703 CE_LOSS :  0.4081614911556244 AUG_LOSS :  22.720874786376953 ]\n",
      "[BATCH_IDX :  240 LOSS :  24.0797176361084 CE_LOSS :  1.1594959497451782 AUG_LOSS :  22.92022132873535 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.47998046875 CE_LOSS :  0.8899068832397461 AUG_LOSS :  22.590072631835938 ]\n",
      "[BATCH_IDX :  280 LOSS :  24.53851890563965 CE_LOSS :  1.2820518016815186 AUG_LOSS :  23.256467819213867 ]\n",
      "[BATCH_IDX :  300 LOSS :  24.273212432861328 CE_LOSS :  1.2153948545455933 AUG_LOSS :  23.057817459106445 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.58026695251465 CE_LOSS :  1.4552005529403687 AUG_LOSS :  22.12506675720215 ]\n",
      "[BATCH_IDX :  340 LOSS :  23.143686294555664 CE_LOSS :  0.5733598470687866 AUG_LOSS :  22.57032585144043 ]\n",
      "[BATCH_IDX :  360 LOSS :  22.60067367553711 CE_LOSS :  0.7732322216033936 AUG_LOSS :  21.827442169189453 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.41436195373535 CE_LOSS :  0.7508399486541748 AUG_LOSS :  22.663522720336914 ]\n",
      "[BATCH_IDX :  400 LOSS :  22.338029861450195 CE_LOSS :  1.015708327293396 AUG_LOSS :  21.32232093811035 ]\n",
      "[BATCH_IDX :  420 LOSS :  23.99479103088379 CE_LOSS :  1.1586369276046753 AUG_LOSS :  22.83615493774414 ]\n",
      "[BATCH_IDX :  440 LOSS :  22.75359535217285 CE_LOSS :  0.47517281770706177 AUG_LOSS :  22.278423309326172 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.158374786376953 CE_LOSS :  1.0795438289642334 AUG_LOSS :  22.07883071899414 ]\n",
      "[BATCH_IDX :  480 LOSS :  22.77694320678711 CE_LOSS :  0.5747418403625488 AUG_LOSS :  22.20220184326172 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.800704956054688 CE_LOSS :  1.4693388938903809 AUG_LOSS :  22.33136558532715 ]\n",
      "[BATCH_IDX :  520 LOSS :  23.56616973876953 CE_LOSS :  1.5700609683990479 AUG_LOSS :  21.996109008789062 ]\n",
      "[BATCH_IDX :  540 LOSS :  23.226106643676758 CE_LOSS :  0.6389231085777283 AUG_LOSS :  22.587182998657227 ]\n",
      "[BATCH_IDX :  560 LOSS :  22.60064697265625 CE_LOSS :  0.7224117517471313 AUG_LOSS :  21.87823486328125 ]\n",
      "[BATCH_IDX :  580 LOSS :  22.573949813842773 CE_LOSS :  0.3542883098125458 AUG_LOSS :  22.219661712646484 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.37944793701172 CE_LOSS :  1.1252756118774414 AUG_LOSS :  22.25417137145996 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.92807388305664 CE_LOSS :  0.5366960763931274 AUG_LOSS :  23.39137840270996 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.14895248413086 CE_LOSS :  0.9331845045089722 AUG_LOSS :  22.215768814086914 ]\n",
      "[BATCH_IDX :  660 LOSS :  22.962139129638672 CE_LOSS :  0.7124528288841248 AUG_LOSS :  22.24968719482422 ]\n",
      "[BATCH_IDX :  680 LOSS :  23.09541130065918 CE_LOSS :  0.9824894070625305 AUG_LOSS :  22.11292266845703 ]\n",
      "[BATCH_IDX :  700 LOSS :  22.22824478149414 CE_LOSS :  0.7623987793922424 AUG_LOSS :  21.465845108032227 ]\n",
      "[BATCH_IDX :  720 LOSS :  22.605724334716797 CE_LOSS :  0.7717657089233398 AUG_LOSS :  21.83395767211914 ]\n",
      "[BATCH_IDX :  740 LOSS :  22.6860294342041 CE_LOSS :  0.3405025601387024 AUG_LOSS :  22.34552764892578 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.45478057861328 CE_LOSS :  1.1737045049667358 AUG_LOSS :  22.281076431274414 ]\n",
      "[BATCH_IDX :  780 LOSS :  24.09400749206543 CE_LOSS :  1.874041199684143 AUG_LOSS :  22.219966888427734 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.268665313720703 CE_LOSS :  0.7371493577957153 AUG_LOSS :  22.53151512145996 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.80833625793457 CE_LOSS :  1.437843918800354 AUG_LOSS :  22.370492935180664 ]\n",
      "[BATCH_IDX :  840 LOSS :  23.876798629760742 CE_LOSS :  0.6723141670227051 AUG_LOSS :  23.204484939575195 ]\n",
      "[BATCH_IDX :  860 LOSS :  23.756425857543945 CE_LOSS :  1.3602012395858765 AUG_LOSS :  22.396224975585938 ]\n",
      "[BATCH_IDX :  880 LOSS :  22.639617919921875 CE_LOSS :  0.8921439051628113 AUG_LOSS :  21.747474670410156 ]\n",
      "[BATCH_IDX :  900 LOSS :  23.084558486938477 CE_LOSS :  1.1886717081069946 AUG_LOSS :  21.89588737487793 ]\n",
      "Epoch : 3\n",
      "[BATCH_IDX :  0 LOSS :  22.317646026611328 CE_LOSS :  0.9627949595451355 AUG_LOSS :  21.35485076904297 ]\n",
      "[BATCH_IDX :  20 LOSS :  22.416032791137695 CE_LOSS :  0.8601781725883484 AUG_LOSS :  21.55585479736328 ]\n",
      "[BATCH_IDX :  40 LOSS :  23.014636993408203 CE_LOSS :  0.9330154657363892 AUG_LOSS :  22.081621170043945 ]\n",
      "[BATCH_IDX :  60 LOSS :  23.884504318237305 CE_LOSS :  1.4708316326141357 AUG_LOSS :  22.413673400878906 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.01030921936035 CE_LOSS :  0.6733216643333435 AUG_LOSS :  22.33698844909668 ]\n",
      "[BATCH_IDX :  100 LOSS :  22.37279510498047 CE_LOSS :  0.5036187767982483 AUG_LOSS :  21.869176864624023 ]\n",
      "[BATCH_IDX :  120 LOSS :  23.36740493774414 CE_LOSS :  1.04119873046875 AUG_LOSS :  22.32620620727539 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.815902709960938 CE_LOSS :  1.0651849508285522 AUG_LOSS :  22.750717163085938 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.065221786499023 CE_LOSS :  0.9498212933540344 AUG_LOSS :  22.115400314331055 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.33405113220215 CE_LOSS :  0.5672050714492798 AUG_LOSS :  21.766845703125 ]\n",
      "[BATCH_IDX :  200 LOSS :  23.14214515686035 CE_LOSS :  0.9021973609924316 AUG_LOSS :  22.239948272705078 ]\n",
      "[BATCH_IDX :  220 LOSS :  22.793922424316406 CE_LOSS :  0.8878766298294067 AUG_LOSS :  21.90604591369629 ]\n",
      "[BATCH_IDX :  240 LOSS :  23.797119140625 CE_LOSS :  1.580199956893921 AUG_LOSS :  22.2169189453125 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.170875549316406 CE_LOSS :  0.5736703276634216 AUG_LOSS :  22.597206115722656 ]\n",
      "[BATCH_IDX :  280 LOSS :  23.369930267333984 CE_LOSS :  0.7947235703468323 AUG_LOSS :  22.575206756591797 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.20133399963379 CE_LOSS :  1.2406567335128784 AUG_LOSS :  21.960678100585938 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  320 LOSS :  22.85939598083496 CE_LOSS :  0.8493660688400269 AUG_LOSS :  22.01003074645996 ]\n",
      "[BATCH_IDX :  340 LOSS :  24.069774627685547 CE_LOSS :  1.4231420755386353 AUG_LOSS :  22.64663314819336 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.13298225402832 CE_LOSS :  1.107054352760315 AUG_LOSS :  22.025928497314453 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.09697151184082 CE_LOSS :  0.7886620759963989 AUG_LOSS :  22.30830955505371 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.548948287963867 CE_LOSS :  0.9827054738998413 AUG_LOSS :  22.566242218017578 ]\n",
      "[BATCH_IDX :  420 LOSS :  22.246957778930664 CE_LOSS :  0.6523185968399048 AUG_LOSS :  21.59463882446289 ]\n",
      "[BATCH_IDX :  440 LOSS :  22.965030670166016 CE_LOSS :  0.5896183252334595 AUG_LOSS :  22.375411987304688 ]\n",
      "[BATCH_IDX :  460 LOSS :  24.501638412475586 CE_LOSS :  1.5679492950439453 AUG_LOSS :  22.93368911743164 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.815216064453125 CE_LOSS :  1.2826488018035889 AUG_LOSS :  22.532567977905273 ]\n",
      "[BATCH_IDX :  500 LOSS :  24.070751190185547 CE_LOSS :  1.7325862646102905 AUG_LOSS :  22.338165283203125 ]\n",
      "[BATCH_IDX :  520 LOSS :  23.615642547607422 CE_LOSS :  0.8267292976379395 AUG_LOSS :  22.78891372680664 ]\n",
      "[BATCH_IDX :  540 LOSS :  24.469053268432617 CE_LOSS :  1.550943374633789 AUG_LOSS :  22.918109893798828 ]\n",
      "[BATCH_IDX :  560 LOSS :  23.543947219848633 CE_LOSS :  0.9988274574279785 AUG_LOSS :  22.545120239257812 ]\n",
      "[BATCH_IDX :  580 LOSS :  23.34947967529297 CE_LOSS :  1.0847365856170654 AUG_LOSS :  22.26474380493164 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.75542449951172 CE_LOSS :  1.3348896503448486 AUG_LOSS :  22.420534133911133 ]\n",
      "[BATCH_IDX :  620 LOSS :  22.58491325378418 CE_LOSS :  0.640866756439209 AUG_LOSS :  21.944046020507812 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.988697052001953 CE_LOSS :  0.9702826738357544 AUG_LOSS :  23.018413543701172 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.45714569091797 CE_LOSS :  0.8028547167778015 AUG_LOSS :  22.6542911529541 ]\n",
      "[BATCH_IDX :  680 LOSS :  22.324565887451172 CE_LOSS :  0.2907324731349945 AUG_LOSS :  22.033832550048828 ]\n",
      "[BATCH_IDX :  700 LOSS :  23.28761100769043 CE_LOSS :  0.464387983083725 AUG_LOSS :  22.823223114013672 ]\n",
      "[BATCH_IDX :  720 LOSS :  22.42150115966797 CE_LOSS :  1.0488989353179932 AUG_LOSS :  21.372602462768555 ]\n",
      "[BATCH_IDX :  740 LOSS :  23.25234603881836 CE_LOSS :  1.4251117706298828 AUG_LOSS :  21.827234268188477 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.135967254638672 CE_LOSS :  1.1453640460968018 AUG_LOSS :  21.990602493286133 ]\n",
      "[BATCH_IDX :  780 LOSS :  22.675451278686523 CE_LOSS :  0.5272514224052429 AUG_LOSS :  22.1481990814209 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.613924026489258 CE_LOSS :  0.8864051103591919 AUG_LOSS :  22.72751808166504 ]\n",
      "[BATCH_IDX :  820 LOSS :  22.801671981811523 CE_LOSS :  0.70984947681427 AUG_LOSS :  22.091821670532227 ]\n",
      "[BATCH_IDX :  840 LOSS :  23.14929962158203 CE_LOSS :  0.9674539566040039 AUG_LOSS :  22.181846618652344 ]\n",
      "[BATCH_IDX :  860 LOSS :  22.709896087646484 CE_LOSS :  1.1364576816558838 AUG_LOSS :  21.57343864440918 ]\n",
      "[BATCH_IDX :  880 LOSS :  22.94068145751953 CE_LOSS :  0.7430977821350098 AUG_LOSS :  22.19758415222168 ]\n",
      "[BATCH_IDX :  900 LOSS :  24.208282470703125 CE_LOSS :  1.742915391921997 AUG_LOSS :  22.46536636352539 ]\n",
      "Epoch : 4\n",
      "[BATCH_IDX :  0 LOSS :  24.07642364501953 CE_LOSS :  1.4026002883911133 AUG_LOSS :  22.6738224029541 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.52397918701172 CE_LOSS :  1.094353199005127 AUG_LOSS :  22.42962646484375 ]\n",
      "[BATCH_IDX :  40 LOSS :  22.614543914794922 CE_LOSS :  0.5549935102462769 AUG_LOSS :  22.059551239013672 ]\n",
      "[BATCH_IDX :  60 LOSS :  23.741565704345703 CE_LOSS :  0.8557515144348145 AUG_LOSS :  22.885814666748047 ]\n",
      "[BATCH_IDX :  80 LOSS :  22.853404998779297 CE_LOSS :  0.6878712177276611 AUG_LOSS :  22.1655330657959 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.533159255981445 CE_LOSS :  1.0457843542099 AUG_LOSS :  22.487375259399414 ]\n",
      "[BATCH_IDX :  120 LOSS :  22.574337005615234 CE_LOSS :  0.8486751317977905 AUG_LOSS :  21.725662231445312 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.8607177734375 CE_LOSS :  1.4017841815948486 AUG_LOSS :  22.458932876586914 ]\n",
      "[BATCH_IDX :  160 LOSS :  22.937313079833984 CE_LOSS :  0.1256585419178009 AUG_LOSS :  22.811655044555664 ]\n",
      "[BATCH_IDX :  180 LOSS :  23.85912322998047 CE_LOSS :  1.7912960052490234 AUG_LOSS :  22.067827224731445 ]\n",
      "[BATCH_IDX :  200 LOSS :  23.39057159423828 CE_LOSS :  0.9312330484390259 AUG_LOSS :  22.459339141845703 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.312641143798828 CE_LOSS :  0.8423953056335449 AUG_LOSS :  22.470245361328125 ]\n",
      "[BATCH_IDX :  240 LOSS :  22.809776306152344 CE_LOSS :  1.1692783832550049 AUG_LOSS :  21.6404972076416 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.156221389770508 CE_LOSS :  1.0385401248931885 AUG_LOSS :  22.1176815032959 ]\n",
      "[BATCH_IDX :  280 LOSS :  23.880197525024414 CE_LOSS :  0.8798959851264954 AUG_LOSS :  23.000301361083984 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.11998748779297 CE_LOSS :  1.33431875705719 AUG_LOSS :  21.785669326782227 ]\n",
      "[BATCH_IDX :  320 LOSS :  22.239458084106445 CE_LOSS :  0.4505630433559418 AUG_LOSS :  21.788894653320312 ]\n",
      "[BATCH_IDX :  340 LOSS :  22.923131942749023 CE_LOSS :  1.1602962017059326 AUG_LOSS :  21.762836456298828 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.37569808959961 CE_LOSS :  1.025058388710022 AUG_LOSS :  22.35063934326172 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.121665954589844 CE_LOSS :  0.8820642232894897 AUG_LOSS :  22.239601135253906 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.16697120666504 CE_LOSS :  0.8249603509902954 AUG_LOSS :  22.342010498046875 ]\n",
      "[BATCH_IDX :  420 LOSS :  23.39742088317871 CE_LOSS :  1.1069648265838623 AUG_LOSS :  22.290456771850586 ]\n",
      "[BATCH_IDX :  440 LOSS :  23.793031692504883 CE_LOSS :  0.8876574635505676 AUG_LOSS :  22.90537452697754 ]\n",
      "[BATCH_IDX :  460 LOSS :  22.37380599975586 CE_LOSS :  0.4786415100097656 AUG_LOSS :  21.895164489746094 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.54488754272461 CE_LOSS :  1.3317371606826782 AUG_LOSS :  22.213150024414062 ]\n",
      "[BATCH_IDX :  500 LOSS :  22.70313835144043 CE_LOSS :  0.6002613306045532 AUG_LOSS :  22.102876663208008 ]\n",
      "[BATCH_IDX :  520 LOSS :  23.207509994506836 CE_LOSS :  0.9860872030258179 AUG_LOSS :  22.22142219543457 ]\n",
      "[BATCH_IDX :  540 LOSS :  23.312082290649414 CE_LOSS :  0.9283038973808289 AUG_LOSS :  22.383777618408203 ]\n",
      "[BATCH_IDX :  560 LOSS :  24.069799423217773 CE_LOSS :  0.9200918078422546 AUG_LOSS :  23.149707794189453 ]\n",
      "[BATCH_IDX :  580 LOSS :  24.013690948486328 CE_LOSS :  0.8066989779472351 AUG_LOSS :  23.20699119567871 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.836257934570312 CE_LOSS :  0.9149753451347351 AUG_LOSS :  22.921281814575195 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.6617374420166 CE_LOSS :  1.3641918897628784 AUG_LOSS :  22.29754638671875 ]\n",
      "[BATCH_IDX :  640 LOSS :  24.174070358276367 CE_LOSS :  1.4814399480819702 AUG_LOSS :  22.692630767822266 ]\n",
      "[BATCH_IDX :  660 LOSS :  24.26189613342285 CE_LOSS :  1.7786023616790771 AUG_LOSS :  22.483293533325195 ]\n",
      "[BATCH_IDX :  680 LOSS :  24.07975959777832 CE_LOSS :  0.9995247721672058 AUG_LOSS :  23.08023452758789 ]\n",
      "[BATCH_IDX :  700 LOSS :  22.75286865234375 CE_LOSS :  0.5167528390884399 AUG_LOSS :  22.236116409301758 ]\n",
      "[BATCH_IDX :  720 LOSS :  23.80843162536621 CE_LOSS :  0.6994887590408325 AUG_LOSS :  23.10894203186035 ]\n",
      "[BATCH_IDX :  740 LOSS :  23.045656204223633 CE_LOSS :  1.1251728534698486 AUG_LOSS :  21.920482635498047 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.07030487060547 CE_LOSS :  1.0076522827148438 AUG_LOSS :  22.062652587890625 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.49607276916504 CE_LOSS :  1.075087070465088 AUG_LOSS :  22.42098617553711 ]\n",
      "[BATCH_IDX :  800 LOSS :  22.55157470703125 CE_LOSS :  0.8225985765457153 AUG_LOSS :  21.728975296020508 ]\n",
      "[BATCH_IDX :  820 LOSS :  24.602336883544922 CE_LOSS :  2.1853270530700684 AUG_LOSS :  22.417009353637695 ]\n",
      "[BATCH_IDX :  840 LOSS :  23.64662742614746 CE_LOSS :  1.7849633693695068 AUG_LOSS :  21.861663818359375 ]\n",
      "[BATCH_IDX :  860 LOSS :  22.98760414123535 CE_LOSS :  0.7051640748977661 AUG_LOSS :  22.282440185546875 ]\n",
      "[BATCH_IDX :  880 LOSS :  24.268508911132812 CE_LOSS :  1.4998066425323486 AUG_LOSS :  22.768701553344727 ]\n",
      "[BATCH_IDX :  900 LOSS :  24.207717895507812 CE_LOSS :  1.627267599105835 AUG_LOSS :  22.5804500579834 ]\n",
      "Epoch : 5\n",
      "[BATCH_IDX :  0 LOSS :  22.334692001342773 CE_LOSS :  0.6883785128593445 AUG_LOSS :  21.646312713623047 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  20 LOSS :  22.95826530456543 CE_LOSS :  0.9326141476631165 AUG_LOSS :  22.025651931762695 ]\n",
      "[BATCH_IDX :  40 LOSS :  23.431737899780273 CE_LOSS :  1.1347019672393799 AUG_LOSS :  22.297035217285156 ]\n",
      "[BATCH_IDX :  60 LOSS :  24.870365142822266 CE_LOSS :  1.9409332275390625 AUG_LOSS :  22.929431915283203 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.546855926513672 CE_LOSS :  0.7973687648773193 AUG_LOSS :  22.749486923217773 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.7030086517334 CE_LOSS :  0.9021127820014954 AUG_LOSS :  22.80089569091797 ]\n",
      "[BATCH_IDX :  120 LOSS :  22.191682815551758 CE_LOSS :  0.4350524842739105 AUG_LOSS :  21.756629943847656 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.067394256591797 CE_LOSS :  0.8109312057495117 AUG_LOSS :  22.25646209716797 ]\n",
      "[BATCH_IDX :  160 LOSS :  24.249454498291016 CE_LOSS :  1.2157105207443237 AUG_LOSS :  23.03374481201172 ]\n",
      "[BATCH_IDX :  180 LOSS :  24.311044692993164 CE_LOSS :  1.4259573221206665 AUG_LOSS :  22.885087966918945 ]\n",
      "[BATCH_IDX :  200 LOSS :  23.032085418701172 CE_LOSS :  0.6024026274681091 AUG_LOSS :  22.429683685302734 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.713184356689453 CE_LOSS :  1.562482237815857 AUG_LOSS :  22.15070152282715 ]\n",
      "[BATCH_IDX :  240 LOSS :  22.509437561035156 CE_LOSS :  0.6077353954315186 AUG_LOSS :  21.901702880859375 ]\n",
      "[BATCH_IDX :  260 LOSS :  24.593761444091797 CE_LOSS :  1.313765287399292 AUG_LOSS :  23.279996871948242 ]\n",
      "[BATCH_IDX :  280 LOSS :  22.42163848876953 CE_LOSS :  0.873438835144043 AUG_LOSS :  21.548198699951172 ]\n",
      "[BATCH_IDX :  300 LOSS :  22.61963653564453 CE_LOSS :  0.2764975428581238 AUG_LOSS :  22.3431396484375 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.075063705444336 CE_LOSS :  0.6349037289619446 AUG_LOSS :  22.440160751342773 ]\n",
      "[BATCH_IDX :  340 LOSS :  22.76242446899414 CE_LOSS :  0.4079359173774719 AUG_LOSS :  22.354488372802734 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.283973693847656 CE_LOSS :  1.3895809650421143 AUG_LOSS :  21.894392013549805 ]\n",
      "[BATCH_IDX :  380 LOSS :  24.212284088134766 CE_LOSS :  1.7348415851593018 AUG_LOSS :  22.477441787719727 ]\n",
      "[BATCH_IDX :  400 LOSS :  22.96222686767578 CE_LOSS :  0.8157656788825989 AUG_LOSS :  22.146461486816406 ]\n",
      "[BATCH_IDX :  420 LOSS :  22.6738338470459 CE_LOSS :  1.0760605335235596 AUG_LOSS :  21.5977725982666 ]\n",
      "[BATCH_IDX :  440 LOSS :  23.784610748291016 CE_LOSS :  1.2375510931015015 AUG_LOSS :  22.547060012817383 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.641206741333008 CE_LOSS :  0.980597198009491 AUG_LOSS :  22.66061019897461 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.92555046081543 CE_LOSS :  1.0579755306243896 AUG_LOSS :  22.86757469177246 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.82752227783203 CE_LOSS :  1.5613253116607666 AUG_LOSS :  22.266197204589844 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.388612747192383 CE_LOSS :  0.7275350689888 AUG_LOSS :  21.66107749938965 ]\n",
      "[BATCH_IDX :  540 LOSS :  23.13141441345215 CE_LOSS :  0.8560770750045776 AUG_LOSS :  22.27533721923828 ]\n",
      "[BATCH_IDX :  560 LOSS :  22.404705047607422 CE_LOSS :  0.7316389679908752 AUG_LOSS :  21.673065185546875 ]\n",
      "[BATCH_IDX :  580 LOSS :  22.903764724731445 CE_LOSS :  0.34103575348854065 AUG_LOSS :  22.562728881835938 ]\n",
      "[BATCH_IDX :  600 LOSS :  22.89706039428711 CE_LOSS :  0.5084757208824158 AUG_LOSS :  22.38858413696289 ]\n",
      "[BATCH_IDX :  620 LOSS :  22.246784210205078 CE_LOSS :  0.42025384306907654 AUG_LOSS :  21.82653045654297 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.62013816833496 CE_LOSS :  1.294872522354126 AUG_LOSS :  22.325265884399414 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.30781364440918 CE_LOSS :  0.6443432569503784 AUG_LOSS :  22.663471221923828 ]\n",
      "[BATCH_IDX :  680 LOSS :  22.596853256225586 CE_LOSS :  0.7939426898956299 AUG_LOSS :  21.80290985107422 ]\n",
      "[BATCH_IDX :  700 LOSS :  22.398149490356445 CE_LOSS :  0.4629269540309906 AUG_LOSS :  21.935222625732422 ]\n",
      "[BATCH_IDX :  720 LOSS :  22.48538589477539 CE_LOSS :  0.32507461309432983 AUG_LOSS :  22.160310745239258 ]\n",
      "[BATCH_IDX :  740 LOSS :  23.222023010253906 CE_LOSS :  1.0414667129516602 AUG_LOSS :  22.18055534362793 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.18025016784668 CE_LOSS :  1.4484211206436157 AUG_LOSS :  21.731828689575195 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.247766494750977 CE_LOSS :  0.3417678773403168 AUG_LOSS :  22.90599822998047 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.709016799926758 CE_LOSS :  1.050807237625122 AUG_LOSS :  22.6582088470459 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.539033889770508 CE_LOSS :  1.899835228919983 AUG_LOSS :  21.639198303222656 ]\n",
      "[BATCH_IDX :  840 LOSS :  22.912189483642578 CE_LOSS :  0.6177404522895813 AUG_LOSS :  22.294448852539062 ]\n",
      "[BATCH_IDX :  860 LOSS :  23.192195892333984 CE_LOSS :  1.0357606410980225 AUG_LOSS :  22.156435012817383 ]\n",
      "[BATCH_IDX :  880 LOSS :  25.392040252685547 CE_LOSS :  2.1444056034088135 AUG_LOSS :  23.247634887695312 ]\n",
      "[BATCH_IDX :  900 LOSS :  24.03023910522461 CE_LOSS :  1.0419187545776367 AUG_LOSS :  22.988319396972656 ]\n",
      "Epoch : 6\n",
      "[BATCH_IDX :  0 LOSS :  23.20174217224121 CE_LOSS :  1.0322115421295166 AUG_LOSS :  22.169530868530273 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.11383819580078 CE_LOSS :  0.7924267053604126 AUG_LOSS :  22.3214111328125 ]\n",
      "[BATCH_IDX :  40 LOSS :  23.052549362182617 CE_LOSS :  1.4576752185821533 AUG_LOSS :  21.594873428344727 ]\n",
      "[BATCH_IDX :  60 LOSS :  23.827112197875977 CE_LOSS :  1.3928413391113281 AUG_LOSS :  22.43427085876465 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.531373977661133 CE_LOSS :  0.6572175025939941 AUG_LOSS :  22.874156951904297 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.124862670898438 CE_LOSS :  0.6764635443687439 AUG_LOSS :  22.44839859008789 ]\n",
      "[BATCH_IDX :  120 LOSS :  23.313526153564453 CE_LOSS :  0.8928259015083313 AUG_LOSS :  22.420700073242188 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.97136688232422 CE_LOSS :  1.5015913248062134 AUG_LOSS :  22.469776153564453 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.750198364257812 CE_LOSS :  1.2676080465316772 AUG_LOSS :  22.482589721679688 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.653797149658203 CE_LOSS :  0.527595579624176 AUG_LOSS :  22.126201629638672 ]\n",
      "[BATCH_IDX :  200 LOSS :  21.765426635742188 CE_LOSS :  0.16852205991744995 AUG_LOSS :  21.596904754638672 ]\n",
      "[BATCH_IDX :  220 LOSS :  22.94902801513672 CE_LOSS :  0.9078116416931152 AUG_LOSS :  22.041215896606445 ]\n",
      "[BATCH_IDX :  240 LOSS :  23.148372650146484 CE_LOSS :  0.7520376443862915 AUG_LOSS :  22.39633560180664 ]\n",
      "[BATCH_IDX :  260 LOSS :  22.79780387878418 CE_LOSS :  0.7003808617591858 AUG_LOSS :  22.097423553466797 ]\n",
      "[BATCH_IDX :  280 LOSS :  24.12140655517578 CE_LOSS :  2.1097187995910645 AUG_LOSS :  22.011688232421875 ]\n",
      "[BATCH_IDX :  300 LOSS :  22.157251358032227 CE_LOSS :  0.5092961192131042 AUG_LOSS :  21.6479549407959 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.965261459350586 CE_LOSS :  1.46696138381958 AUG_LOSS :  22.498300552368164 ]\n",
      "[BATCH_IDX :  340 LOSS :  24.013050079345703 CE_LOSS :  1.2548243999481201 AUG_LOSS :  22.75822639465332 ]\n",
      "[BATCH_IDX :  360 LOSS :  22.87311553955078 CE_LOSS :  0.6183458566665649 AUG_LOSS :  22.254770278930664 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.42424964904785 CE_LOSS :  0.6540906429290771 AUG_LOSS :  22.770158767700195 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.13707160949707 CE_LOSS :  0.865096926689148 AUG_LOSS :  22.271974563598633 ]\n",
      "[BATCH_IDX :  420 LOSS :  24.4583740234375 CE_LOSS :  1.247025728225708 AUG_LOSS :  23.211347579956055 ]\n",
      "[BATCH_IDX :  440 LOSS :  23.356889724731445 CE_LOSS :  1.0531052350997925 AUG_LOSS :  22.30378532409668 ]\n",
      "[BATCH_IDX :  460 LOSS :  22.403339385986328 CE_LOSS :  0.48350444436073303 AUG_LOSS :  21.91983413696289 ]\n",
      "[BATCH_IDX :  480 LOSS :  24.073698043823242 CE_LOSS :  1.5816936492919922 AUG_LOSS :  22.49200439453125 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.99460792541504 CE_LOSS :  0.9179564714431763 AUG_LOSS :  23.076650619506836 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.682777404785156 CE_LOSS :  1.2342422008514404 AUG_LOSS :  21.448535919189453 ]\n",
      "[BATCH_IDX :  540 LOSS :  24.022859573364258 CE_LOSS :  1.4194092750549316 AUG_LOSS :  22.603450775146484 ]\n",
      "[BATCH_IDX :  560 LOSS :  23.800247192382812 CE_LOSS :  0.5883854627609253 AUG_LOSS :  23.211862564086914 ]\n",
      "[BATCH_IDX :  580 LOSS :  22.776212692260742 CE_LOSS :  0.6125673651695251 AUG_LOSS :  22.163644790649414 ]\n",
      "[BATCH_IDX :  600 LOSS :  23.135120391845703 CE_LOSS :  1.2712796926498413 AUG_LOSS :  21.863840103149414 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.07671356201172 CE_LOSS :  0.6211777925491333 AUG_LOSS :  22.455535888671875 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  640 LOSS :  23.470108032226562 CE_LOSS :  0.9905996322631836 AUG_LOSS :  22.479507446289062 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.928781509399414 CE_LOSS :  1.6184552907943726 AUG_LOSS :  22.310325622558594 ]\n",
      "[BATCH_IDX :  680 LOSS :  23.28629493713379 CE_LOSS :  0.49718061089515686 AUG_LOSS :  22.789113998413086 ]\n",
      "[BATCH_IDX :  700 LOSS :  23.765644073486328 CE_LOSS :  1.175018072128296 AUG_LOSS :  22.590625762939453 ]\n",
      "[BATCH_IDX :  720 LOSS :  22.67774200439453 CE_LOSS :  0.7297993898391724 AUG_LOSS :  21.94794273376465 ]\n",
      "[BATCH_IDX :  740 LOSS :  22.309890747070312 CE_LOSS :  0.473261296749115 AUG_LOSS :  21.83662986755371 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.057228088378906 CE_LOSS :  0.6073676347732544 AUG_LOSS :  22.449859619140625 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.105045318603516 CE_LOSS :  0.8107409477233887 AUG_LOSS :  22.29430389404297 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.761539459228516 CE_LOSS :  0.8338583111763 AUG_LOSS :  22.92768096923828 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.5264949798584 CE_LOSS :  0.5941047072410583 AUG_LOSS :  22.932390213012695 ]\n",
      "[BATCH_IDX :  840 LOSS :  22.444360733032227 CE_LOSS :  0.4656502306461334 AUG_LOSS :  21.978710174560547 ]\n",
      "[BATCH_IDX :  860 LOSS :  22.641090393066406 CE_LOSS :  1.3153769969940186 AUG_LOSS :  21.325714111328125 ]\n",
      "[BATCH_IDX :  880 LOSS :  23.887773513793945 CE_LOSS :  2.021714448928833 AUG_LOSS :  21.866058349609375 ]\n",
      "[BATCH_IDX :  900 LOSS :  22.765674591064453 CE_LOSS :  0.8555557131767273 AUG_LOSS :  21.910118103027344 ]\n",
      "Epoch : 7\n",
      "[BATCH_IDX :  0 LOSS :  23.263641357421875 CE_LOSS :  0.8576481938362122 AUG_LOSS :  22.40599250793457 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.268386840820312 CE_LOSS :  0.7041270136833191 AUG_LOSS :  22.564260482788086 ]\n",
      "[BATCH_IDX :  40 LOSS :  22.78599739074707 CE_LOSS :  0.3557857275009155 AUG_LOSS :  22.430212020874023 ]\n",
      "[BATCH_IDX :  60 LOSS :  22.65790557861328 CE_LOSS :  0.5775617361068726 AUG_LOSS :  22.08034324645996 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.630136489868164 CE_LOSS :  0.8809057474136353 AUG_LOSS :  22.749231338500977 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.77004051208496 CE_LOSS :  1.7521016597747803 AUG_LOSS :  22.0179386138916 ]\n",
      "[BATCH_IDX :  120 LOSS :  21.93482780456543 CE_LOSS :  0.731110692024231 AUG_LOSS :  21.203716278076172 ]\n",
      "[BATCH_IDX :  140 LOSS :  22.36266326904297 CE_LOSS :  0.38756078481674194 AUG_LOSS :  21.9751033782959 ]\n",
      "[BATCH_IDX :  160 LOSS :  24.984342575073242 CE_LOSS :  2.28328275680542 AUG_LOSS :  22.701059341430664 ]\n",
      "[BATCH_IDX :  180 LOSS :  24.025604248046875 CE_LOSS :  1.3682012557983398 AUG_LOSS :  22.65740203857422 ]\n",
      "[BATCH_IDX :  200 LOSS :  24.100767135620117 CE_LOSS :  1.1075937747955322 AUG_LOSS :  22.993173599243164 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.18090057373047 CE_LOSS :  1.2720195055007935 AUG_LOSS :  21.90888023376465 ]\n",
      "[BATCH_IDX :  240 LOSS :  23.592374801635742 CE_LOSS :  0.7279836535453796 AUG_LOSS :  22.864391326904297 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.318870544433594 CE_LOSS :  1.1497223377227783 AUG_LOSS :  22.169147491455078 ]\n",
      "[BATCH_IDX :  280 LOSS :  21.875694274902344 CE_LOSS :  0.43474888801574707 AUG_LOSS :  21.44094467163086 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.565753936767578 CE_LOSS :  1.296326994895935 AUG_LOSS :  22.269426345825195 ]\n",
      "[BATCH_IDX :  320 LOSS :  24.109455108642578 CE_LOSS :  2.146538496017456 AUG_LOSS :  21.96291732788086 ]\n",
      "[BATCH_IDX :  340 LOSS :  22.452882766723633 CE_LOSS :  0.7890334129333496 AUG_LOSS :  21.663848876953125 ]\n",
      "[BATCH_IDX :  360 LOSS :  24.18317222595215 CE_LOSS :  1.3632152080535889 AUG_LOSS :  22.819957733154297 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.084064483642578 CE_LOSS :  0.5054820775985718 AUG_LOSS :  22.578582763671875 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.26698875427246 CE_LOSS :  0.7142065167427063 AUG_LOSS :  22.55278205871582 ]\n",
      "[BATCH_IDX :  420 LOSS :  23.342430114746094 CE_LOSS :  1.0333878993988037 AUG_LOSS :  22.30904197692871 ]\n",
      "[BATCH_IDX :  440 LOSS :  24.862131118774414 CE_LOSS :  2.0785555839538574 AUG_LOSS :  22.7835750579834 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.401575088500977 CE_LOSS :  1.0793073177337646 AUG_LOSS :  22.322267532348633 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.426137924194336 CE_LOSS :  1.3589246273040771 AUG_LOSS :  22.06721305847168 ]\n",
      "[BATCH_IDX :  500 LOSS :  24.66398048400879 CE_LOSS :  2.3337483406066895 AUG_LOSS :  22.330232620239258 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.836950302124023 CE_LOSS :  0.3241617679595947 AUG_LOSS :  22.512788772583008 ]\n",
      "[BATCH_IDX :  540 LOSS :  22.002168655395508 CE_LOSS :  0.5214499235153198 AUG_LOSS :  21.4807186126709 ]\n",
      "[BATCH_IDX :  560 LOSS :  23.873559951782227 CE_LOSS :  1.1782947778701782 AUG_LOSS :  22.69526481628418 ]\n",
      "[BATCH_IDX :  580 LOSS :  23.48052406311035 CE_LOSS :  0.8794251680374146 AUG_LOSS :  22.601099014282227 ]\n",
      "[BATCH_IDX :  600 LOSS :  22.78513526916504 CE_LOSS :  0.5965939164161682 AUG_LOSS :  22.188541412353516 ]\n",
      "[BATCH_IDX :  620 LOSS :  22.75494384765625 CE_LOSS :  0.6921576857566833 AUG_LOSS :  22.062786102294922 ]\n",
      "[BATCH_IDX :  640 LOSS :  24.16129493713379 CE_LOSS :  1.2246630191802979 AUG_LOSS :  22.93663215637207 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.776687622070312 CE_LOSS :  0.5390851497650146 AUG_LOSS :  23.23760223388672 ]\n",
      "[BATCH_IDX :  680 LOSS :  23.866962432861328 CE_LOSS :  1.2784448862075806 AUG_LOSS :  22.588518142700195 ]\n",
      "[BATCH_IDX :  700 LOSS :  23.272911071777344 CE_LOSS :  0.9437069892883301 AUG_LOSS :  22.329204559326172 ]\n",
      "[BATCH_IDX :  720 LOSS :  23.236909866333008 CE_LOSS :  0.8609468340873718 AUG_LOSS :  22.37596321105957 ]\n",
      "[BATCH_IDX :  740 LOSS :  23.813766479492188 CE_LOSS :  1.2758550643920898 AUG_LOSS :  22.537912368774414 ]\n",
      "[BATCH_IDX :  760 LOSS :  22.879640579223633 CE_LOSS :  0.8955284953117371 AUG_LOSS :  21.984111785888672 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.795942306518555 CE_LOSS :  1.3659045696258545 AUG_LOSS :  22.430038452148438 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.23479461669922 CE_LOSS :  1.351733922958374 AUG_LOSS :  21.883060455322266 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.496570587158203 CE_LOSS :  1.220532774925232 AUG_LOSS :  22.276037216186523 ]\n",
      "[BATCH_IDX :  840 LOSS :  22.83864974975586 CE_LOSS :  0.9340778589248657 AUG_LOSS :  21.904571533203125 ]\n",
      "[BATCH_IDX :  860 LOSS :  23.283599853515625 CE_LOSS :  0.6790581941604614 AUG_LOSS :  22.604541778564453 ]\n",
      "[BATCH_IDX :  880 LOSS :  23.491836547851562 CE_LOSS :  0.8436177968978882 AUG_LOSS :  22.648218154907227 ]\n",
      "[BATCH_IDX :  900 LOSS :  23.194232940673828 CE_LOSS :  0.9945917129516602 AUG_LOSS :  22.199642181396484 ]\n",
      "Epoch : 8\n",
      "[BATCH_IDX :  0 LOSS :  23.63780403137207 CE_LOSS :  0.830705463886261 AUG_LOSS :  22.807098388671875 ]\n",
      "[BATCH_IDX :  20 LOSS :  22.62938690185547 CE_LOSS :  0.6304144263267517 AUG_LOSS :  21.998971939086914 ]\n",
      "[BATCH_IDX :  40 LOSS :  22.523717880249023 CE_LOSS :  0.6125643849372864 AUG_LOSS :  21.91115379333496 ]\n",
      "[BATCH_IDX :  60 LOSS :  24.34646987915039 CE_LOSS :  1.741753339767456 AUG_LOSS :  22.604717254638672 ]\n",
      "[BATCH_IDX :  80 LOSS :  23.31072425842285 CE_LOSS :  0.8338071703910828 AUG_LOSS :  22.476917266845703 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.005125045776367 CE_LOSS :  0.3916521966457367 AUG_LOSS :  22.61347198486328 ]\n",
      "[BATCH_IDX :  120 LOSS :  22.015106201171875 CE_LOSS :  0.7089401483535767 AUG_LOSS :  21.30616569519043 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.76923179626465 CE_LOSS :  1.3804203271865845 AUG_LOSS :  22.388811111450195 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.123687744140625 CE_LOSS :  0.7419715523719788 AUG_LOSS :  22.381715774536133 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.380523681640625 CE_LOSS :  0.8696870803833008 AUG_LOSS :  21.51083755493164 ]\n",
      "[BATCH_IDX :  200 LOSS :  25.004150390625 CE_LOSS :  1.8793541193008423 AUG_LOSS :  23.12479591369629 ]\n",
      "[BATCH_IDX :  220 LOSS :  24.0124568939209 CE_LOSS :  1.1430866718292236 AUG_LOSS :  22.869369506835938 ]\n",
      "[BATCH_IDX :  240 LOSS :  23.672035217285156 CE_LOSS :  1.6284914016723633 AUG_LOSS :  22.043542861938477 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.73442840576172 CE_LOSS :  0.7175752520561218 AUG_LOSS :  23.01685333251953 ]\n",
      "[BATCH_IDX :  280 LOSS :  23.569684982299805 CE_LOSS :  0.8233082890510559 AUG_LOSS :  22.746376037597656 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.272918701171875 CE_LOSS :  1.1168975830078125 AUG_LOSS :  22.156021118164062 ]\n",
      "[BATCH_IDX :  320 LOSS :  24.1347713470459 CE_LOSS :  0.7933027148246765 AUG_LOSS :  23.341468811035156 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  340 LOSS :  22.37851333618164 CE_LOSS :  0.9992860555648804 AUG_LOSS :  21.379226684570312 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.530197143554688 CE_LOSS :  0.6911457777023315 AUG_LOSS :  22.839052200317383 ]\n",
      "[BATCH_IDX :  380 LOSS :  22.051589965820312 CE_LOSS :  0.389198362827301 AUG_LOSS :  21.662391662597656 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.320589065551758 CE_LOSS :  1.0440330505371094 AUG_LOSS :  22.27655601501465 ]\n",
      "[BATCH_IDX :  420 LOSS :  23.829410552978516 CE_LOSS :  1.1521724462509155 AUG_LOSS :  22.67723846435547 ]\n",
      "[BATCH_IDX :  440 LOSS :  22.401018142700195 CE_LOSS :  0.38730281591415405 AUG_LOSS :  22.013715744018555 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.374502182006836 CE_LOSS :  1.1477634906768799 AUG_LOSS :  22.22673797607422 ]\n",
      "[BATCH_IDX :  480 LOSS :  24.20378875732422 CE_LOSS :  1.303061604499817 AUG_LOSS :  22.900726318359375 ]\n",
      "[BATCH_IDX :  500 LOSS :  24.503175735473633 CE_LOSS :  2.8085272312164307 AUG_LOSS :  21.69464874267578 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.280696868896484 CE_LOSS :  0.5174473524093628 AUG_LOSS :  21.76325035095215 ]\n",
      "[BATCH_IDX :  540 LOSS :  23.66147232055664 CE_LOSS :  0.5791093111038208 AUG_LOSS :  23.08236312866211 ]\n",
      "[BATCH_IDX :  560 LOSS :  22.919113159179688 CE_LOSS :  0.7850948572158813 AUG_LOSS :  22.134017944335938 ]\n",
      "[BATCH_IDX :  580 LOSS :  23.39226722717285 CE_LOSS :  0.43847399950027466 AUG_LOSS :  22.953792572021484 ]\n",
      "[BATCH_IDX :  600 LOSS :  22.22066307067871 CE_LOSS :  0.190721333026886 AUG_LOSS :  22.02994155883789 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.561901092529297 CE_LOSS :  1.5103322267532349 AUG_LOSS :  22.05156898498535 ]\n",
      "[BATCH_IDX :  640 LOSS :  23.756195068359375 CE_LOSS :  1.211276888847351 AUG_LOSS :  22.544918060302734 ]\n",
      "[BATCH_IDX :  660 LOSS :  23.996795654296875 CE_LOSS :  0.7067490816116333 AUG_LOSS :  23.29004669189453 ]\n",
      "[BATCH_IDX :  680 LOSS :  24.140167236328125 CE_LOSS :  1.8820974826812744 AUG_LOSS :  22.25806999206543 ]\n",
      "[BATCH_IDX :  700 LOSS :  24.189678192138672 CE_LOSS :  1.700130820274353 AUG_LOSS :  22.489547729492188 ]\n",
      "[BATCH_IDX :  720 LOSS :  22.781354904174805 CE_LOSS :  0.6189468502998352 AUG_LOSS :  22.16240882873535 ]\n",
      "[BATCH_IDX :  740 LOSS :  22.481891632080078 CE_LOSS :  0.24908944964408875 AUG_LOSS :  22.23280143737793 ]\n",
      "[BATCH_IDX :  760 LOSS :  25.131298065185547 CE_LOSS :  2.005300760269165 AUG_LOSS :  23.12599754333496 ]\n",
      "[BATCH_IDX :  780 LOSS :  23.265533447265625 CE_LOSS :  1.109295129776001 AUG_LOSS :  22.156238555908203 ]\n",
      "[BATCH_IDX :  800 LOSS :  23.674596786499023 CE_LOSS :  0.8205990791320801 AUG_LOSS :  22.8539981842041 ]\n",
      "[BATCH_IDX :  820 LOSS :  22.525711059570312 CE_LOSS :  0.6336897015571594 AUG_LOSS :  21.89202117919922 ]\n",
      "[BATCH_IDX :  840 LOSS :  22.646587371826172 CE_LOSS :  0.7414544820785522 AUG_LOSS :  21.905132293701172 ]\n",
      "[BATCH_IDX :  860 LOSS :  24.128652572631836 CE_LOSS :  2.2534797191619873 AUG_LOSS :  21.875173568725586 ]\n",
      "[BATCH_IDX :  880 LOSS :  22.299339294433594 CE_LOSS :  0.3046981692314148 AUG_LOSS :  21.994640350341797 ]\n",
      "[BATCH_IDX :  900 LOSS :  24.944110870361328 CE_LOSS :  2.6347596645355225 AUG_LOSS :  22.309350967407227 ]\n",
      "Epoch : 9\n",
      "[BATCH_IDX :  0 LOSS :  23.97469139099121 CE_LOSS :  1.9069621562957764 AUG_LOSS :  22.067729949951172 ]\n",
      "[BATCH_IDX :  20 LOSS :  23.189298629760742 CE_LOSS :  0.6291224360466003 AUG_LOSS :  22.560176849365234 ]\n",
      "[BATCH_IDX :  40 LOSS :  24.065654754638672 CE_LOSS :  1.0013929605484009 AUG_LOSS :  23.06426239013672 ]\n",
      "[BATCH_IDX :  60 LOSS :  23.980117797851562 CE_LOSS :  1.7263133525848389 AUG_LOSS :  22.25380516052246 ]\n",
      "[BATCH_IDX :  80 LOSS :  24.491504669189453 CE_LOSS :  2.3754241466522217 AUG_LOSS :  22.11608123779297 ]\n",
      "[BATCH_IDX :  100 LOSS :  21.52766227722168 CE_LOSS :  0.43617624044418335 AUG_LOSS :  21.09148597717285 ]\n",
      "[BATCH_IDX :  120 LOSS :  25.169034957885742 CE_LOSS :  2.134809970855713 AUG_LOSS :  23.034225463867188 ]\n",
      "[BATCH_IDX :  140 LOSS :  22.844440460205078 CE_LOSS :  0.6016930341720581 AUG_LOSS :  22.242748260498047 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.064599990844727 CE_LOSS :  0.7507684230804443 AUG_LOSS :  22.313831329345703 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.072938919067383 CE_LOSS :  0.7065892219543457 AUG_LOSS :  21.366350173950195 ]\n",
      "[BATCH_IDX :  200 LOSS :  22.993852615356445 CE_LOSS :  1.0384165048599243 AUG_LOSS :  21.95543670654297 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.090576171875 CE_LOSS :  0.638105034828186 AUG_LOSS :  22.452470779418945 ]\n",
      "[BATCH_IDX :  240 LOSS :  22.931316375732422 CE_LOSS :  0.41761985421180725 AUG_LOSS :  22.513696670532227 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.875680923461914 CE_LOSS :  1.3407639265060425 AUG_LOSS :  22.5349178314209 ]\n",
      "[BATCH_IDX :  280 LOSS :  23.375774383544922 CE_LOSS :  0.6477586627006531 AUG_LOSS :  22.728015899658203 ]\n",
      "[BATCH_IDX :  300 LOSS :  24.005802154541016 CE_LOSS :  1.0533647537231445 AUG_LOSS :  22.952436447143555 ]\n",
      "[BATCH_IDX :  320 LOSS :  23.66828727722168 CE_LOSS :  0.8959659337997437 AUG_LOSS :  22.772321701049805 ]\n",
      "[BATCH_IDX :  340 LOSS :  24.020124435424805 CE_LOSS :  1.4342764616012573 AUG_LOSS :  22.585847854614258 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.524065017700195 CE_LOSS :  1.4086477756500244 AUG_LOSS :  22.11541748046875 ]\n",
      "[BATCH_IDX :  380 LOSS :  23.281702041625977 CE_LOSS :  0.8169502019882202 AUG_LOSS :  22.464752197265625 ]\n",
      "[BATCH_IDX :  400 LOSS :  24.013431549072266 CE_LOSS :  1.0516475439071655 AUG_LOSS :  22.96178436279297 ]\n",
      "[BATCH_IDX :  420 LOSS :  22.749032974243164 CE_LOSS :  1.4012200832366943 AUG_LOSS :  21.34781265258789 ]\n",
      "[BATCH_IDX :  440 LOSS :  24.330928802490234 CE_LOSS :  2.0431485176086426 AUG_LOSS :  22.28778076171875 ]\n",
      "[BATCH_IDX :  460 LOSS :  24.204923629760742 CE_LOSS :  1.109544038772583 AUG_LOSS :  23.095378875732422 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.016986846923828 CE_LOSS :  0.7398568987846375 AUG_LOSS :  22.277130126953125 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.30491065979004 CE_LOSS :  0.8387187123298645 AUG_LOSS :  22.4661922454834 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.811779022216797 CE_LOSS :  0.6275397539138794 AUG_LOSS :  22.18423843383789 ]\n",
      "[BATCH_IDX :  540 LOSS :  23.129241943359375 CE_LOSS :  1.143615484237671 AUG_LOSS :  21.985626220703125 ]\n",
      "[BATCH_IDX :  560 LOSS :  22.48310661315918 CE_LOSS :  0.5081924200057983 AUG_LOSS :  21.97491455078125 ]\n",
      "[BATCH_IDX :  580 LOSS :  23.71703338623047 CE_LOSS :  1.6589254140853882 AUG_LOSS :  22.058107376098633 ]\n",
      "[BATCH_IDX :  600 LOSS :  24.039552688598633 CE_LOSS :  1.1311795711517334 AUG_LOSS :  22.90837287902832 ]\n",
      "[BATCH_IDX :  620 LOSS :  23.983753204345703 CE_LOSS :  1.4085921049118042 AUG_LOSS :  22.57516098022461 ]\n",
      "[BATCH_IDX :  640 LOSS :  22.244516372680664 CE_LOSS :  0.36008602380752563 AUG_LOSS :  21.884429931640625 ]\n",
      "[BATCH_IDX :  660 LOSS :  22.726274490356445 CE_LOSS :  0.5734285116195679 AUG_LOSS :  22.15284538269043 ]\n",
      "[BATCH_IDX :  680 LOSS :  22.75897216796875 CE_LOSS :  0.8364093899726868 AUG_LOSS :  21.922563552856445 ]\n",
      "[BATCH_IDX :  700 LOSS :  25.51129913330078 CE_LOSS :  3.0717926025390625 AUG_LOSS :  22.43950653076172 ]\n",
      "[BATCH_IDX :  720 LOSS :  23.027755737304688 CE_LOSS :  0.6200250387191772 AUG_LOSS :  22.407730102539062 ]\n",
      "[BATCH_IDX :  740 LOSS :  24.493078231811523 CE_LOSS :  1.4312942028045654 AUG_LOSS :  23.061784744262695 ]\n",
      "[BATCH_IDX :  760 LOSS :  23.14827537536621 CE_LOSS :  0.6943543553352356 AUG_LOSS :  22.453920364379883 ]\n",
      "[BATCH_IDX :  780 LOSS :  24.0352725982666 CE_LOSS :  1.5431894063949585 AUG_LOSS :  22.492082595825195 ]\n",
      "[BATCH_IDX :  800 LOSS :  21.948278427124023 CE_LOSS :  0.11687631905078888 AUG_LOSS :  21.831401824951172 ]\n",
      "[BATCH_IDX :  820 LOSS :  23.350605010986328 CE_LOSS :  1.5464895963668823 AUG_LOSS :  21.804115295410156 ]\n",
      "[BATCH_IDX :  840 LOSS :  22.974943161010742 CE_LOSS :  0.5481435060501099 AUG_LOSS :  22.426799774169922 ]\n",
      "[BATCH_IDX :  860 LOSS :  22.783416748046875 CE_LOSS :  0.8872316479682922 AUG_LOSS :  21.89618492126465 ]\n",
      "[BATCH_IDX :  880 LOSS :  23.140342712402344 CE_LOSS :  1.0071622133255005 AUG_LOSS :  22.133180618286133 ]\n",
      "[BATCH_IDX :  900 LOSS :  22.829856872558594 CE_LOSS :  1.1273871660232544 AUG_LOSS :  21.702468872070312 ]\n",
      "Epoch : 10\n",
      "[BATCH_IDX :  0 LOSS :  23.04729461669922 CE_LOSS :  1.44569730758667 AUG_LOSS :  21.60159683227539 ]\n",
      "[BATCH_IDX :  20 LOSS :  24.237010955810547 CE_LOSS :  2.4967856407165527 AUG_LOSS :  21.740224838256836 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH_IDX :  40 LOSS :  24.049020767211914 CE_LOSS :  1.2200195789337158 AUG_LOSS :  22.82900047302246 ]\n",
      "[BATCH_IDX :  60 LOSS :  22.937108993530273 CE_LOSS :  0.6210450530052185 AUG_LOSS :  22.316064834594727 ]\n",
      "[BATCH_IDX :  80 LOSS :  22.105670928955078 CE_LOSS :  0.5953255891799927 AUG_LOSS :  21.510345458984375 ]\n",
      "[BATCH_IDX :  100 LOSS :  23.673871994018555 CE_LOSS :  2.0955421924591064 AUG_LOSS :  21.57832908630371 ]\n",
      "[BATCH_IDX :  120 LOSS :  24.054494857788086 CE_LOSS :  1.3420275449752808 AUG_LOSS :  22.712467193603516 ]\n",
      "[BATCH_IDX :  140 LOSS :  23.46622085571289 CE_LOSS :  1.5180621147155762 AUG_LOSS :  21.948158264160156 ]\n",
      "[BATCH_IDX :  160 LOSS :  23.217004776000977 CE_LOSS :  0.6680790185928345 AUG_LOSS :  22.548925399780273 ]\n",
      "[BATCH_IDX :  180 LOSS :  22.93289566040039 CE_LOSS :  0.7963413000106812 AUG_LOSS :  22.136554718017578 ]\n",
      "[BATCH_IDX :  200 LOSS :  22.97323989868164 CE_LOSS :  0.7411280870437622 AUG_LOSS :  22.23211097717285 ]\n",
      "[BATCH_IDX :  220 LOSS :  23.313018798828125 CE_LOSS :  0.9802232980728149 AUG_LOSS :  22.332796096801758 ]\n",
      "[BATCH_IDX :  240 LOSS :  24.267187118530273 CE_LOSS :  1.800146460533142 AUG_LOSS :  22.467041015625 ]\n",
      "[BATCH_IDX :  260 LOSS :  23.846633911132812 CE_LOSS :  1.2095434665679932 AUG_LOSS :  22.6370906829834 ]\n",
      "[BATCH_IDX :  280 LOSS :  22.59958267211914 CE_LOSS :  0.528683066368103 AUG_LOSS :  22.070899963378906 ]\n",
      "[BATCH_IDX :  300 LOSS :  23.059431076049805 CE_LOSS :  0.7508749961853027 AUG_LOSS :  22.308555603027344 ]\n",
      "[BATCH_IDX :  320 LOSS :  24.314712524414062 CE_LOSS :  1.4573240280151367 AUG_LOSS :  22.85738754272461 ]\n",
      "[BATCH_IDX :  340 LOSS :  25.520112991333008 CE_LOSS :  2.942596435546875 AUG_LOSS :  22.577516555786133 ]\n",
      "[BATCH_IDX :  360 LOSS :  23.254222869873047 CE_LOSS :  0.9316880106925964 AUG_LOSS :  22.322534561157227 ]\n",
      "[BATCH_IDX :  380 LOSS :  22.482624053955078 CE_LOSS :  1.1383448839187622 AUG_LOSS :  21.34427833557129 ]\n",
      "[BATCH_IDX :  400 LOSS :  23.178285598754883 CE_LOSS :  0.86088627576828 AUG_LOSS :  22.317399978637695 ]\n",
      "[BATCH_IDX :  420 LOSS :  23.680864334106445 CE_LOSS :  1.4276047945022583 AUG_LOSS :  22.253259658813477 ]\n",
      "[BATCH_IDX :  440 LOSS :  23.075042724609375 CE_LOSS :  0.7365573644638062 AUG_LOSS :  22.338485717773438 ]\n",
      "[BATCH_IDX :  460 LOSS :  23.363737106323242 CE_LOSS :  0.7679868936538696 AUG_LOSS :  22.59575080871582 ]\n",
      "[BATCH_IDX :  480 LOSS :  23.13791275024414 CE_LOSS :  0.8557155728340149 AUG_LOSS :  22.282197952270508 ]\n",
      "[BATCH_IDX :  500 LOSS :  23.732017517089844 CE_LOSS :  0.9382527470588684 AUG_LOSS :  22.793764114379883 ]\n",
      "[BATCH_IDX :  520 LOSS :  22.163923263549805 CE_LOSS :  0.431179940700531 AUG_LOSS :  21.732744216918945 ]\n",
      "[BATCH_IDX :  540 LOSS :  24.62059211730957 CE_LOSS :  1.3285248279571533 AUG_LOSS :  23.29206657409668 ]\n",
      "[BATCH_IDX :  560 LOSS :  23.37998390197754 CE_LOSS :  0.5625395178794861 AUG_LOSS :  22.81744384765625 ]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "    print(\"Epoch : %d\"% (epoch))\n",
    "    \n",
    "    for batch_idx, (inputs1, inputs2, indexes) in enumerate(trainloader):\n",
    "        inputs1, inputs2, indexes = inputs1.cuda(), inputs2.cuda(), indexes.cuda()           \n",
    "        batch_size = inputs1.shape[0]\n",
    "        labels = p_label[indexes].cuda()\n",
    "        inputs = torch.cat([inputs1, inputs2])\n",
    "        outputs = model(inputs)\n",
    "        outputs=outputs.reshape(-1,1280)\n",
    "        outputs1 = outputs[:batch_size]\n",
    "        outputs2 = outputs[batch_size:]\n",
    "        outputs3 = fc(outputs1)\n",
    "        ce_loss = criterion(outputs3, labels)\n",
    "        aug_loss = criterion2(outputs1, outputs2) / 30\n",
    "        loss = ce_loss + aug_loss\n",
    "        optimizer.zero_grad()\n",
    "        optimizer1.zero_grad()\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\"[BATCH_IDX : \", batch_idx, \"LOSS : \",loss.item(), \"CE_LOSS : \",ce_loss.item(),\"AUG_LOSS : \",aug_loss.item(),\"]\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/haoying/res_zl12_effnet_v4')\n",
    "torch.save(model, 'city.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nature\n",
    "clusterset = GPSDataset('/home/haoying/res_zl12_effnet_v3/nightlights_labeled0.csv', '/home/haoying/data_zl12/', cluster_transform)\n",
    "trainset = GPSDataset('/home/haoying/res_zl12_effnet_v3/nightlights_labeled0.csv', '/home/haoying/data_zl12/', train_transform1, train_transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/haoying/res_zl12_effnet_v4/res_pretrained.pt')\n",
    "model._fc = nn.Identity()\n",
    "model._swish = nn.Identity()\n",
    "# model = nn.Sequential(*(list(model.children())[:-3])) # strips off last linear layer\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10086, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_ = features\n",
    "pca = PCA(n_components = 0.80) \n",
    "pca.fit(X_)\n",
    "reduced_X = pca.transform(X_)\n",
    "reduced_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means loss evolution: [5909.20996094 3241.57470703 3117.0402832  3055.37329102 3022.85375977\n",
      " 2995.59643555 2966.43139648 2942.66821289 2926.94213867 2916.28930664\n",
      " 2910.00683594 2906.57275391 2904.62109375 2903.6237793  2903.13427734\n",
      " 2902.8137207  2902.61132812 2902.4128418  2902.14379883 2901.40576172]\n",
      "tensor([1, 0, 7,  ..., 4, 4, 5], device='cuda:0')\n",
      "k-means time: 1 s\n"
     ]
    }
   ],
   "source": [
    "clusterloader = torch.utils.data.DataLoader(clusterset, batch_size=20, shuffle=False, num_workers=0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20, shuffle=True, num_workers=0, drop_last = True)\n",
    "deepcluster = Kmeans(8)\n",
    "\n",
    "features = compute_features(clusterloader, model, len(clusterset), 20) \n",
    "clustering_loss, p_label = deepcluster.cluster(features,pca=31)\n",
    "p_label = p_label.tolist()\n",
    "p_label = torch.tensor(p_label).cuda()\n",
    "model.train()\n",
    "\n",
    "fc = nn.Linear(1280,8)\n",
    "fc.weight.data.normal_(0, 0.01)\n",
    "fc.bias.data.zero_()\n",
    "fc.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "optimizer1 = torch.optim.SGD(fc.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_211731/60422569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch : %d\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "    print(\"Epoch : %d\"% (epoch))\n",
    "    \n",
    "    for batch_idx, (inputs1, inputs2, indexes) in enumerate(trainloader):\n",
    "        inputs1, inputs2, indexes = inputs1.cuda(), inputs2.cuda(), indexes.cuda()           \n",
    "        batch_size = inputs1.shape[0]\n",
    "        labels = p_label[indexes].cuda()\n",
    "        inputs = torch.cat([inputs1, inputs2])\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.reshape(-1,1280)\n",
    "        outputs1 = outputs[:batch_size]\n",
    "        outputs2 = outputs[batch_size:]\n",
    "        outputs3 = fc(outputs1)\n",
    "        ce_loss = criterion(outputs3, labels)\n",
    "        aug_loss = criterion2(outputs1, outputs2) / 50\n",
    "        loss = ce_loss + aug_loss\n",
    "        optimizer.zero_grad()\n",
    "        optimizer1.zero_grad()\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\"[BATCH_IDX : \", batch_idx, \"LOSS : \",loss.item(), \"CE_LOSS : \",ce_loss.item(),\"AUG_LOSS : \",aug_loss.item(),\"]\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/haoying/res_zl12_effnet_v4')\n",
    "torch.save(model, 'nature.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
